{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 5: Input Embedder v2 (Boltz-2)\n",
    "\n",
    "Enhanced input embedding for Boltz-2.\n",
    "\n",
    "## Source Code Location\n",
    "- **File**: `Boltz-Ref-src/boltz-official/src/boltz/model/modules/trunkv2.py`\n",
    "- **Class**: `InputEmbedder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "def layer_norm(x, eps=1e-5):\n",
    "    mean = np.mean(x, axis=-1, keepdims=True)\n",
    "    var = np.var(x, axis=-1, keepdims=True)\n",
    "    return (x - mean) / np.sqrt(var + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_encoder(atom_features, atom_to_token, c_atom=64):\n",
    "    \"\"\"Encode atom features to token level.\"\"\"\n",
    "    N_atoms = atom_features.shape[0]\n",
    "    N_tokens = atom_to_token.max() + 1\n",
    "    \n",
    "    # Simple mean pooling per token\n",
    "    token_features = np.zeros((N_tokens, c_atom))\n",
    "    counts = np.zeros(N_tokens)\n",
    "    \n",
    "    for a in range(N_atoms):\n",
    "        t = atom_to_token[a]\n",
    "        token_features[t] += atom_features[a]\n",
    "        counts[t] += 1\n",
    "    \n",
    "    token_features = token_features / np.maximum(counts[:, None], 1)\n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_embedder_v2(res_type, profile, deletion_mean, pocket_feature, \n",
    "                       atom_features=None, atom_to_token=None, token_s=384):\n",
    "    \"\"\"\n",
    "    Input Embedder v2 for Boltz-2.\n",
    "    \n",
    "    Enhanced with better atom encoding and pocket features.\n",
    "    \n",
    "    Args:\n",
    "        res_type: Residue type one-hot [N, 32]\n",
    "        profile: MSA profile [N, 32]\n",
    "        deletion_mean: Deletion frequency [N]\n",
    "        pocket_feature: Pocket indicators [N, pocket_dim]\n",
    "        atom_features: Per-atom features [N_atoms, c_atom]\n",
    "        atom_to_token: Atom to token mapping [N_atoms]\n",
    "        token_s: Output dimension\n",
    "    \n",
    "    Returns:\n",
    "        Token embeddings [N, token_s]\n",
    "    \"\"\"\n",
    "    N = res_type.shape[0]\n",
    "    \n",
    "    print(f\"Input Embedder v2 (Boltz-2)\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Tokens: {N}\")\n",
    "    \n",
    "    # Atom features (enhanced in v2)\n",
    "    if atom_features is not None and atom_to_token is not None:\n",
    "        atom_emb = atom_encoder(atom_features, atom_to_token, c_atom=64)\n",
    "        # Project to token_s\n",
    "        W_atom = np.random.randn(64, token_s) * (64 ** -0.5)\n",
    "        atom_emb = atom_emb @ W_atom\n",
    "        print(f\"  Atom features encoded\")\n",
    "    else:\n",
    "        atom_emb = np.zeros((N, token_s))\n",
    "    \n",
    "    # Expand deletion_mean\n",
    "    deletion_mean = deletion_mean[:, np.newaxis]\n",
    "    \n",
    "    # Concatenate all features\n",
    "    features = np.concatenate([\n",
    "        atom_emb,\n",
    "        res_type,\n",
    "        profile,\n",
    "        deletion_mean,\n",
    "        pocket_feature,\n",
    "    ], axis=-1)\n",
    "    \n",
    "    print(f\"  Combined features: {features.shape}\")\n",
    "    \n",
    "    # Project to token dimension\n",
    "    W = np.random.randn(features.shape[-1], token_s) * (features.shape[-1] ** -0.5)\n",
    "    output = features @ W\n",
    "    \n",
    "    print(f\"  Output: {output.shape}\")\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "print(\"Test: Input Embedder v2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "N = 50\n",
    "N_atoms = 200\n",
    "\n",
    "res_type = np.eye(32)[np.random.randint(0, 20, N)]\n",
    "profile = np.random.dirichlet(np.ones(32), N)\n",
    "deletion_mean = np.random.uniform(0, 0.5, N)\n",
    "pocket_feature = np.random.randint(0, 2, (N, 4)).astype(np.float32)\n",
    "\n",
    "# With atom features\n",
    "atom_features = np.random.randn(N_atoms, 64)\n",
    "atom_to_token = np.random.randint(0, N, N_atoms)\n",
    "\n",
    "output = input_embedder_v2(\n",
    "    res_type, profile, deletion_mean, pocket_feature,\n",
    "    atom_features, atom_to_token, token_s=256\n",
    ")\n",
    "\n",
    "print(f\"\\nOutput finite: {np.isfinite(output).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Enhanced Atom Encoding**: Better atomâ†’token aggregation\n",
    "2. **Pocket Features**: Important for drug binding\n",
    "3. **Unified Embedding**: Combines all input modalities\n",
    "4. **Ligand Support**: Works for proteins and small molecules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.8.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
