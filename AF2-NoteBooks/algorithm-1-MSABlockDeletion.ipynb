{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 1: MSA Block Deletion\n",
    "\n",
    "MSA Block Deletion is a data augmentation technique used during training. It randomly deletes contiguous blocks of sequences from the MSA to improve model robustness and prevent overfitting.\n",
    "\n",
    "## Algorithm Pseudocode\n",
    "\n",
    "![MSA Block Deletion](../imgs/algorithms/MSABlockDeletion.png)\n",
    "\n",
    "## Source Code Location\n",
    "- **File**: `AF2-source-code/model/tf/data_transforms.py`\n",
    "- **Function**: `sample_msa`, `make_msa_mask`\n",
    "- **Lines**: 214-250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The MSA Block Deletion algorithm serves several purposes:\n",
    "\n",
    "1. **Data Augmentation**: Varies training data by randomly removing MSA sequences\n",
    "2. **Robustness**: Forces model to work with varying MSA depths\n",
    "3. **Generalization**: Prevents overfitting to specific MSA patterns\n",
    "4. **Efficiency**: Reduces computation by working with smaller MSAs during training\n",
    "\n",
    "### Algorithm Steps\n",
    "\n",
    "1. Always keep the first sequence (query sequence)\n",
    "2. Randomly sample which additional sequences to keep\n",
    "3. Ensure minimum number of sequences is maintained\n",
    "4. Return the subsampled MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msa_block_deletion(\n",
    "    msa,\n",
    "    msa_mask=None,\n",
    "    max_seq=512,\n",
    "    deletion_mean=0.1,\n",
    "    keep_query=True\n",
    "):\n",
    "    \"\"\"\n",
    "    MSA Block Deletion - Algorithm 1.\n",
    "    \n",
    "    Randomly samples sequences from MSA, implementing data augmentation\n",
    "    for training robustness.\n",
    "    \n",
    "    Args:\n",
    "        msa: MSA array [N_seq, N_res] amino acid indices\n",
    "        msa_mask: Optional mask [N_seq, N_res] for valid positions\n",
    "        max_seq: Maximum number of sequences to keep\n",
    "        deletion_mean: Mean deletion rate (Bernoulli parameter)\n",
    "        keep_query: Whether to always keep the first sequence\n",
    "    \n",
    "    Returns:\n",
    "        sampled_msa: Subsampled MSA [N_sampled, N_res]\n",
    "        sampled_mask: Subsampled mask [N_sampled, N_res] (if msa_mask provided)\n",
    "    \"\"\"\n",
    "    N_seq, N_res = msa.shape\n",
    "    \n",
    "    if msa_mask is None:\n",
    "        msa_mask = np.ones((N_seq, N_res), dtype=np.float32)\n",
    "    \n",
    "    print(f\"MSA Block Deletion\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Input MSA: [{N_seq}, {N_res}]\")\n",
    "    print(f\"Max sequences: {max_seq}\")\n",
    "    print(f\"Deletion mean: {deletion_mean}\")\n",
    "    \n",
    "    # Step 1: Always keep query (first sequence)\n",
    "    if keep_query:\n",
    "        query_msa = msa[:1]\n",
    "        query_mask = msa_mask[:1]\n",
    "        remaining_msa = msa[1:]\n",
    "        remaining_mask = msa_mask[1:]\n",
    "        max_extra = max_seq - 1\n",
    "    else:\n",
    "        query_msa = np.empty((0, N_res), dtype=msa.dtype)\n",
    "        query_mask = np.empty((0, N_res), dtype=msa_mask.dtype)\n",
    "        remaining_msa = msa\n",
    "        remaining_mask = msa_mask\n",
    "        max_extra = max_seq\n",
    "    \n",
    "    N_remaining = remaining_msa.shape[0]\n",
    "    \n",
    "    # Step 2: Randomly sample which sequences to keep\n",
    "    # Using Bernoulli sampling with given mean\n",
    "    keep_prob = 1.0 - deletion_mean\n",
    "    keep_mask = np.random.random(N_remaining) < keep_prob\n",
    "    \n",
    "    # Step 3: Apply sampling\n",
    "    indices = np.where(keep_mask)[0]\n",
    "    \n",
    "    # Step 4: Limit to max_extra sequences\n",
    "    if len(indices) > max_extra:\n",
    "        # Randomly select max_extra from kept sequences\n",
    "        selected_indices = np.random.choice(indices, size=max_extra, replace=False)\n",
    "        selected_indices = np.sort(selected_indices)  # Keep original order\n",
    "    else:\n",
    "        selected_indices = indices\n",
    "    \n",
    "    # Extract selected sequences\n",
    "    if len(selected_indices) > 0:\n",
    "        selected_msa = remaining_msa[selected_indices]\n",
    "        selected_mask = remaining_mask[selected_indices]\n",
    "    else:\n",
    "        selected_msa = np.empty((0, N_res), dtype=msa.dtype)\n",
    "        selected_mask = np.empty((0, N_res), dtype=msa_mask.dtype)\n",
    "    \n",
    "    # Step 5: Concatenate query with selected sequences\n",
    "    sampled_msa = np.concatenate([query_msa, selected_msa], axis=0)\n",
    "    sampled_mask = np.concatenate([query_mask, selected_mask], axis=0)\n",
    "    \n",
    "    print(f\"\\nSampling Results:\")\n",
    "    print(f\"  Kept {len(selected_indices)} / {N_remaining} extra sequences\")\n",
    "    print(f\"  Output MSA: [{sampled_msa.shape[0]}, {sampled_msa.shape[1]}]\")\n",
    "    print(f\"  Deletion rate: {1 - len(selected_indices)/max(N_remaining, 1):.2%}\")\n",
    "    \n",
    "    return sampled_msa, sampled_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustered MSA Sampling\n",
    "\n",
    "AlphaFold2 also uses cluster-based sampling to maintain diversity while reducing MSA size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_msa_by_cluster(\n",
    "    msa,\n",
    "    cluster_ids,\n",
    "    max_clusters=512,\n",
    "    max_extra_msa=5120\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample MSA using cluster-based approach.\n",
    "    \n",
    "    Keeps cluster centers and samples additional sequences.\n",
    "    \n",
    "    Args:\n",
    "        msa: Full MSA [N_seq, N_res]\n",
    "        cluster_ids: Cluster assignment for each sequence [N_seq]\n",
    "        max_clusters: Maximum number of clusters for main MSA\n",
    "        max_extra_msa: Maximum extra MSA sequences\n",
    "    \n",
    "    Returns:\n",
    "        clustered_msa: Main MSA with cluster centers\n",
    "        extra_msa: Additional MSA sequences\n",
    "    \"\"\"\n",
    "    N_seq, N_res = msa.shape\n",
    "    \n",
    "    # Get unique clusters and their first occurrence (centers)\n",
    "    unique_clusters, first_idx = np.unique(cluster_ids, return_index=True)\n",
    "    \n",
    "    # Sort by first occurrence to maintain order\n",
    "    order = np.argsort(first_idx)\n",
    "    center_indices = first_idx[order]\n",
    "    \n",
    "    print(f\"Cluster-based MSA Sampling\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Total sequences: {N_seq}\")\n",
    "    print(f\"Unique clusters: {len(unique_clusters)}\")\n",
    "    \n",
    "    # Limit clusters\n",
    "    if len(center_indices) > max_clusters:\n",
    "        center_indices = center_indices[:max_clusters]\n",
    "    \n",
    "    # Get cluster centers as main MSA\n",
    "    clustered_msa = msa[center_indices]\n",
    "    \n",
    "    # Remaining sequences for extra MSA\n",
    "    all_indices = set(range(N_seq))\n",
    "    center_set = set(center_indices)\n",
    "    extra_indices = np.array(list(all_indices - center_set))\n",
    "    \n",
    "    # Sample extra MSA\n",
    "    if len(extra_indices) > max_extra_msa:\n",
    "        selected = np.random.choice(extra_indices, size=max_extra_msa, replace=False)\n",
    "        extra_msa = msa[np.sort(selected)]\n",
    "    else:\n",
    "        extra_msa = msa[extra_indices] if len(extra_indices) > 0 else np.empty((0, N_res), dtype=msa.dtype)\n",
    "    \n",
    "    print(f\"\\nOutput:\")\n",
    "    print(f\"  Clustered MSA: {clustered_msa.shape}\")\n",
    "    print(f\"  Extra MSA: {extra_msa.shape}\")\n",
    "    \n",
    "    return clustered_msa, extra_msa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Basic MSA Block Deletion\n",
    "print(\"Test 1: Basic MSA Block Deletion\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create synthetic MSA\n",
    "N_seq, N_res = 1000, 64\n",
    "msa = np.random.randint(0, 21, size=(N_seq, N_res))\n",
    "\n",
    "# Test with different deletion rates\n",
    "for deletion_mean in [0.1, 0.3, 0.5, 0.7]:\n",
    "    np.random.seed(42)  # Reset for reproducibility\n",
    "    sampled_msa, _ = msa_block_deletion(\n",
    "        msa, \n",
    "        max_seq=512, \n",
    "        deletion_mean=deletion_mean\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Verify query preservation\n",
    "print(\"Test 2: Verify Query Preservation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "N_seq, N_res = 100, 32\n",
    "msa = np.random.randint(0, 21, size=(N_seq, N_res))\n",
    "\n",
    "# Mark query with special pattern for identification\n",
    "msa[0, :] = np.arange(N_res) % 21\n",
    "\n",
    "sampled_msa, _ = msa_block_deletion(msa, max_seq=50, deletion_mean=0.5)\n",
    "\n",
    "# Verify query is preserved\n",
    "query_match = np.array_equal(sampled_msa[0], msa[0])\n",
    "print(f\"\\nQuery preserved: {query_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Cluster-based sampling\n",
    "print(\"Test 3: Cluster-Based Sampling\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "N_seq, N_res = 10000, 64\n",
    "msa = np.random.randint(0, 21, size=(N_seq, N_res))\n",
    "\n",
    "# Create synthetic cluster assignments\n",
    "n_clusters = 800\n",
    "cluster_ids = np.random.randint(0, n_clusters, size=N_seq)\n",
    "\n",
    "clustered_msa, extra_msa = sample_msa_by_cluster(\n",
    "    msa, \n",
    "    cluster_ids, \n",
    "    max_clusters=512, \n",
    "    max_extra_msa=5120\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Statistical verification\n",
    "print(\"\\nTest 4: Statistical Verification\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "N_seq, N_res = 1000, 32\n",
    "msa = np.random.randint(0, 21, size=(N_seq, N_res))\n",
    "\n",
    "# Run multiple trials\n",
    "n_trials = 100\n",
    "deletion_mean = 0.3\n",
    "kept_counts = []\n",
    "\n",
    "for _ in range(n_trials):\n",
    "    sampled_msa, _ = msa_block_deletion(\n",
    "        msa, \n",
    "        max_seq=1000,  # No limit \n",
    "        deletion_mean=deletion_mean\n",
    "    )\n",
    "    kept_counts.append(sampled_msa.shape[0])\n",
    "\n",
    "# Remove query from count\n",
    "extra_kept = np.array(kept_counts) - 1\n",
    "expected_kept = (N_seq - 1) * (1 - deletion_mean)\n",
    "\n",
    "print(f\"\\nStatistical Summary ({n_trials} trials):\")\n",
    "print(f\"  Expected extra sequences: {expected_kept:.1f}\")\n",
    "print(f\"  Observed mean: {extra_kept.mean():.1f}\")\n",
    "print(f\"  Observed std: {extra_kept.std():.1f}\")\n",
    "print(f\"  Error: {abs(extra_kept.mean() - expected_kept):.2f} ({abs(extra_kept.mean() - expected_kept)/expected_kept*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification: Key Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verification: Key Properties\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "N_seq, N_res = 500, 64\n",
    "msa = np.random.randint(0, 21, size=(N_seq, N_res))\n",
    "\n",
    "# Property 1: Output never exceeds max_seq\n",
    "max_seq = 128\n",
    "all_valid = True\n",
    "for _ in range(50):\n",
    "    sampled, _ = msa_block_deletion(msa, max_seq=max_seq, deletion_mean=0.1)\n",
    "    if sampled.shape[0] > max_seq:\n",
    "        all_valid = False\n",
    "        break\n",
    "print(f\"Property 1 - Output ≤ max_seq: {all_valid}\")\n",
    "\n",
    "# Property 2: Query always first\n",
    "msa[0, :] = 99  # Mark query\n",
    "sampled, _ = msa_block_deletion(msa, max_seq=128, deletion_mean=0.5)\n",
    "print(f\"Property 2 - Query first: {np.all(sampled[0] == 99)}\")\n",
    "\n",
    "# Property 3: Output is subset of input\n",
    "sampled, _ = msa_block_deletion(msa, max_seq=128, deletion_mean=0.5)\n",
    "is_subset = all(\n",
    "    any(np.array_equal(sampled[i], msa[j]) for j in range(N_seq))\n",
    "    for i in range(sampled.shape[0])\n",
    ")\n",
    "print(f\"Property 3 - Output ⊆ Input: {is_subset}\")\n",
    "\n",
    "# Property 4: Mask consistency\n",
    "msa_mask = np.random.rand(N_seq, N_res) > 0.1\n",
    "msa_mask = msa_mask.astype(np.float32)\n",
    "sampled_msa, sampled_mask = msa_block_deletion(msa, msa_mask, max_seq=128)\n",
    "print(f\"Property 4 - Mask shape matches: {sampled_msa.shape == sampled_mask.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Reference\n",
    "\n",
    "```python\n",
    "# From AF2-source-code/model/tf/data_transforms.py\n",
    "\n",
    "def sample_msa(batch, max_seq, keep_extra, seed=None):\n",
    "  \"\"\"Sample MSA randomly, keeping max_seq sequences.\n",
    "  \n",
    "  Jumper et al. (2021) Suppl. Alg. 1 \"MSABlockDeletion\"\n",
    "  \n",
    "  This implements the MSA subsampling described in the supplementary.\n",
    "  The first sequence (query) is always kept.\n",
    "  \"\"\"\n",
    "  num_seq = batch['msa'].shape[0]\n",
    "  \n",
    "  # Keep query sequence\n",
    "  shuffled = tf.random.shuffle(tf.range(1, num_seq), seed=seed)\n",
    "  index_order = tf.concat([[0], shuffled], axis=0)\n",
    "  \n",
    "  # Keep at most max_seq\n",
    "  num_sel = tf.minimum(max_seq, num_seq)\n",
    "  sel_indices = index_order[:num_sel]\n",
    "  \n",
    "  # Apply to all MSA-related features\n",
    "  for k in ['msa', 'deletion_matrix', 'msa_mask', 'bert_mask']:\n",
    "    if k in batch:\n",
    "      batch[k] = tf.gather(batch[k], sel_indices)\n",
    "  \n",
    "  return batch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Query Preservation**: The first sequence (query/target) is always kept as it represents the protein we're trying to predict.\n",
    "\n",
    "2. **Random Sampling**: Remaining sequences are randomly sampled, providing data augmentation during training.\n",
    "\n",
    "3. **Bounded Output**: The output MSA size is bounded by `max_seq`, ensuring consistent memory usage.\n",
    "\n",
    "4. **Cluster-Based Sampling**: AlphaFold2 uses clustering to maintain MSA diversity while reducing size, keeping cluster centers for the main MSA and additional sequences for the \"extra MSA\".\n",
    "\n",
    "5. **Two MSA Tracks**: The main MSA (~512 sequences) goes through full Evoformer, while extra MSA (~5000 sequences) uses more efficient global attention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
