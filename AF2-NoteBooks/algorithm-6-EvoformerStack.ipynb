{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 6: Evoformer Stack\n",
    "\n",
    "The **Evoformer** is the central neural network component of AlphaFold2, responsible for processing and refining the Multiple Sequence Alignment (MSA) representation and the pair representation. This iterative refinement process enables the model to learn complex evolutionary and structural relationships between residues.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Evoformer stack consists of multiple blocks, each containing several attention and update mechanisms:\n",
    "- **MSA Row Attention with Pair Bias** (Algorithm 7)\n",
    "- **MSA Column Attention** (Algorithm 8)  \n",
    "- **MSA Transition** (Algorithm 9)\n",
    "- **Outer Product Mean** (Algorithm 10)\n",
    "- **Triangle Multiplication** (Algorithms 11, 12)\n",
    "- **Triangle Attention** (Algorithms 13, 14)\n",
    "- **Pair Transition** (Algorithm 15)\n",
    "\n",
    "## Algorithm Pseudocode\n",
    "\n",
    "![Evoformer Stack Algorithm](../imgs/algorithms/EvoformerStack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "### 1. MSA Representation\n",
    "The MSA representation `m` has shape `[N_seq, N_res, c_m]` where:\n",
    "- `N_seq`: Number of sequences in the MSA\n",
    "- `N_res`: Number of residues (sequence length)\n",
    "- `c_m`: MSA channel dimension (typically 256)\n",
    "\n",
    "### 2. Pair Representation\n",
    "The pair representation `z` has shape `[N_res, N_res, c_z]` where:\n",
    "- `c_z`: Pair channel dimension (typically 128)\n",
    "\n",
    "This represents pairwise relationships between all residue pairs.\n",
    "\n",
    "### 3. Information Flow\n",
    "The Evoformer enables bidirectional information flow:\n",
    "- **MSA → Pair**: Via Outer Product Mean, evolutionary information from MSA updates pair representation\n",
    "- **Pair → MSA**: Via MSA Row Attention with Pair Bias, structural information biases MSA attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Implementation\n",
    "\n",
    "The Evoformer is implemented in `AF2-source-code/model/modules.py`. Let's examine the key components:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvoformerIteration Class\n",
    "\n",
    "Each iteration of the Evoformer stack is defined in the `EvoformerIteration` class:\n",
    "\n",
    "```python\n",
    "class EvoformerIteration(hk.Module):\n",
    "  \"\"\"Single iteration (block) of Evoformer stack.\n",
    "\n",
    "  Jumper et al. (2021) Suppl. Alg. 6 \"EvoformerStack\" lines 2-10\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, config, global_config, is_extra_msa,\n",
    "               name='evoformer_iteration'):\n",
    "    super().__init__(name=name)\n",
    "    self.config = config\n",
    "    self.global_config = global_config\n",
    "    self.is_extra_msa = is_extra_msa\n",
    "```\n",
    "\n",
    "The `is_extra_msa` flag determines whether to use regular MSA Column Attention or the more efficient Global Column Attention for processing the extra MSA sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Forward Pass\n",
    "\n",
    "The `__call__` method implements the forward pass following the algorithm pseudocode:\n",
    "\n",
    "```python\n",
    "def __call__(self, activations, masks, is_training=True, safe_key=None):\n",
    "    c = self.config\n",
    "    gc = self.global_config\n",
    "\n",
    "    msa_act, pair_act = activations['msa'], activations['pair']\n",
    "    msa_mask, pair_mask = masks['msa'], masks['pair']\n",
    "\n",
    "    dropout_wrapper_fn = functools.partial(\n",
    "        dropout_wrapper,\n",
    "        is_training=is_training,\n",
    "        global_config=gc)\n",
    "\n",
    "    safe_key, *sub_keys = safe_key.split(10)\n",
    "    sub_keys = iter(sub_keys)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: MSA Row Attention with Pair Bias (Line 3)\n",
    "\n",
    "```python\n",
    "    # Algorithm 7: MSA row-wise gated self-attention with pair bias\n",
    "    msa_act = dropout_wrapper_fn(\n",
    "        MSARowAttentionWithPairBias(\n",
    "            c.msa_row_attention_with_pair_bias, gc,\n",
    "            name='msa_row_attention_with_pair_bias'),\n",
    "        msa_act,\n",
    "        msa_mask,\n",
    "        safe_key=next(sub_keys),\n",
    "        pair_act=pair_act)\n",
    "```\n",
    "\n",
    "This step applies self-attention along each row of the MSA, allowing each position to attend to all other positions within the same sequence. The pair representation provides additional bias to guide the attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: MSA Column Attention (Line 4)\n",
    "\n",
    "```python\n",
    "    # Algorithm 8: MSA column-wise gated self-attention\n",
    "    if not self.is_extra_msa:\n",
    "      attn_mod = MSAColumnAttention(\n",
    "          c.msa_column_attention, gc, name='msa_column_attention')\n",
    "    else:\n",
    "      # Algorithm 19: MSA column-wise global attention (for extra MSA)\n",
    "      attn_mod = MSAColumnGlobalAttention(\n",
    "          c.msa_column_attention, gc, name='msa_column_global_attention')\n",
    "    msa_act = dropout_wrapper_fn(\n",
    "        attn_mod,\n",
    "        msa_act,\n",
    "        msa_mask,\n",
    "        safe_key=next(sub_keys))\n",
    "```\n",
    "\n",
    "Column attention allows each residue position to attend across all sequences in the MSA, enabling the model to learn evolutionary patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: MSA Transition (Line 5)\n",
    "\n",
    "```python\n",
    "    # Algorithm 9: MSA Transition\n",
    "    msa_act = dropout_wrapper_fn(\n",
    "        Transition(c.msa_transition, gc, name='msa_transition'),\n",
    "        msa_act,\n",
    "        msa_mask,\n",
    "        safe_key=next(sub_keys))\n",
    "```\n",
    "\n",
    "A simple feed-forward transition layer to further process the MSA representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Outer Product Mean (Line 6)\n",
    "\n",
    "```python\n",
    "    # Algorithm 10: Outer Product Mean\n",
    "    # Updates pair representation using information from MSA\n",
    "    pair_act = dropout_wrapper_fn(\n",
    "        OuterProductMean(\n",
    "            config=c.outer_product_mean,\n",
    "            global_config=self.global_config,\n",
    "            num_output_channel=int(pair_act.shape[-1]),\n",
    "            name='outer_product_mean'),\n",
    "        msa_act,\n",
    "        msa_mask,\n",
    "        safe_key=next(sub_keys),\n",
    "        output_act=pair_act)\n",
    "```\n",
    "\n",
    "This crucial step computes the outer product of MSA features and averages across sequences to update the pair representation. This is how evolutionary covariance information is transferred to the pair representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Triangle Multiplications (Lines 7-8)\n",
    "\n",
    "```python\n",
    "    # Algorithm 11: Triangle Multiplication (Outgoing)\n",
    "    pair_act = dropout_wrapper_fn(\n",
    "        TriangleMultiplication(c.triangle_multiplication_outgoing, gc,\n",
    "                               name='triangle_multiplication_outgoing'),\n",
    "        pair_act,\n",
    "        pair_mask,\n",
    "        safe_key=next(sub_keys))\n",
    "    \n",
    "    # Algorithm 12: Triangle Multiplication (Incoming)\n",
    "    pair_act = dropout_wrapper_fn(\n",
    "        TriangleMultiplication(c.triangle_multiplication_incoming, gc,\n",
    "                               name='triangle_multiplication_incoming'),\n",
    "        pair_act,\n",
    "        pair_mask,\n",
    "        safe_key=next(sub_keys))\n",
    "```\n",
    "\n",
    "Triangle multiplication updates edge (i,j) by aggregating information from triangles involving that edge. The \"outgoing\" variant aggregates via edges (i,k), while \"incoming\" uses edges (k,j)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Triangle Attention (Lines 9-10)\n",
    "\n",
    "```python\n",
    "    # Algorithm 13: Triangle Attention (Starting Node)\n",
    "    pair_act = dropout_wrapper_fn(\n",
    "        TriangleAttention(c.triangle_attention_starting_node, gc,\n",
    "                          name='triangle_attention_starting_node'),\n",
    "        pair_act,\n",
    "        pair_mask,\n",
    "        safe_key=next(sub_keys))\n",
    "    \n",
    "    # Algorithm 14: Triangle Attention (Ending Node)\n",
    "    pair_act = dropout_wrapper_fn(\n",
    "        TriangleAttention(c.triangle_attention_ending_node, gc,\n",
    "                          name='triangle_attention_ending_node'),\n",
    "        pair_act,\n",
    "        pair_mask,\n",
    "        safe_key=next(sub_keys))\n",
    "```\n",
    "\n",
    "Triangle attention applies self-attention along rows or columns of the pair representation, with additional biases from the pair representation itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Pair Transition (Line 11)\n",
    "\n",
    "```python\n",
    "    # Algorithm 15: Pair Transition\n",
    "    pair_act = dropout_wrapper_fn(\n",
    "        Transition(c.pair_transition, gc, name='pair_transition'),\n",
    "        pair_act,\n",
    "        pair_mask,\n",
    "        safe_key=next(sub_keys))\n",
    "\n",
    "    return {'msa': msa_act, 'pair': pair_act}\n",
    "```\n",
    "\n",
    "A feed-forward transition layer to finalize the pair representation update for this iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Evoformer Blocks\n",
    "\n",
    "The full Evoformer stack is created in `EmbeddingsAndEvoformer` using `layer_stack`:\n",
    "\n",
    "```python\n",
    "# Main trunk of the network\n",
    "# Jumper et al. (2021) Suppl. Alg. 2 \"Inference\" lines 17-18\n",
    "evoformer_iteration = EvoformerIteration(\n",
    "    c.evoformer, gc, is_extra_msa=False, name='evoformer_iteration')\n",
    "\n",
    "def evoformer_fn(x):\n",
    "  act, safe_key = x\n",
    "  safe_key, safe_subkey = safe_key.split()\n",
    "  evoformer_output = evoformer_iteration(\n",
    "      activations=act,\n",
    "      masks=evoformer_masks,\n",
    "      is_training=is_training,\n",
    "      safe_key=safe_subkey)\n",
    "  return (evoformer_output, safe_key)\n",
    "\n",
    "if gc.use_remat:\n",
    "  evoformer_fn = hk.remat(evoformer_fn)\n",
    "\n",
    "evoformer_stack = layer_stack.layer_stack(c.evoformer_num_block)(\n",
    "    evoformer_fn)\n",
    "evoformer_output, safe_key = evoformer_stack(\n",
    "    (evoformer_input, safe_key))\n",
    "```\n",
    "\n",
    "The default configuration uses **48 Evoformer blocks** for the main MSA and **4 blocks** for the extra MSA stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Wrapper\n",
    "\n",
    "The `dropout_wrapper` function implements residual connections with dropout:\n",
    "\n",
    "```python\n",
    "def dropout_wrapper(module,\n",
    "                    input_act,\n",
    "                    mask,\n",
    "                    safe_key,\n",
    "                    global_config,\n",
    "                    output_act=None,\n",
    "                    is_training=True,\n",
    "                    **kwargs):\n",
    "  \"\"\"Applies module + dropout + residual update.\"\"\"\n",
    "  if output_act is None:\n",
    "    output_act = input_act\n",
    "\n",
    "  residual = module(input_act, mask, is_training=is_training, **kwargs)\n",
    "  dropout_rate = 0.0 if gc.deterministic else module.config.dropout_rate\n",
    "\n",
    "  if module.config.shared_dropout:\n",
    "    if module.config.orientation == 'per_row':\n",
    "      broadcast_dim = 0\n",
    "    else:\n",
    "      broadcast_dim = 1\n",
    "  else:\n",
    "    broadcast_dim = None\n",
    "\n",
    "  residual = apply_dropout(tensor=residual,\n",
    "                           safe_key=safe_key,\n",
    "                           rate=dropout_rate,\n",
    "                           is_training=is_training,\n",
    "                           broadcast_dim=broadcast_dim)\n",
    "\n",
    "  new_act = output_act + residual\n",
    "  return new_act\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Design Principles\n",
    "\n",
    "1. **Bidirectional Information Flow**: MSA and pair representations mutually inform each other\n",
    "\n",
    "2. **Triangle Updates**: Enforce geometric consistency in the pair representation (if i is close to j and j is close to k, then i should be close to k)\n",
    "\n",
    "3. **Residual Connections**: Every sub-module uses residual connections for stable training\n",
    "\n",
    "4. **Shared Dropout**: Row-wise or column-wise dropout is shared across the appropriate dimension\n",
    "\n",
    "5. **Gradient Checkpointing**: `hk.remat` is used to reduce memory consumption during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The Evoformer stack is the core innovation of AlphaFold2, enabling:\n",
    "\n",
    "1. **Evolutionary information extraction** from MSA via column attention\n",
    "2. **Structural constraint propagation** through triangle updates\n",
    "3. **Coevolution signal extraction** via outer product mean\n",
    "4. **Deep feature refinement** through 48 stacked blocks\n",
    "\n",
    "The output representations from the Evoformer are then used by the Structure Module to generate the final 3D coordinates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
