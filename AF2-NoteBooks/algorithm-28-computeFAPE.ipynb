{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 28: computeFAPE (Frame Aligned Point Error)\n",
    "\n",
    "FAPE is the primary structural loss function in AlphaFold2. It measures the error between predicted and ground truth atom positions in a way that is invariant to global rotations and translations, by aligning each residue's local frame.\n",
    "\n",
    "## Algorithm Pseudocode\n",
    "\n",
    "![computeFAPE](../imgs/algorithms/computeFAPE.png)\n",
    "\n",
    "## Source Code Location\n",
    "- **File**: `AF2-source-code/model/all_atom.py`\n",
    "- **Function**: `frame_aligned_point_error`\n",
    "- **Lines**: 1025-1100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "### Why FAPE?\n",
    "\n",
    "Traditional RMSD measures global alignment error. FAPE instead:\n",
    "1. For each residue frame, compute the error of ALL atoms when aligned to that frame\n",
    "2. This captures both global structure and local geometry\n",
    "3. Invariant to global rotation/translation\n",
    "\n",
    "### Mathematical Definition\n",
    "\n",
    "$$\\text{FAPE} = \\frac{1}{N_{frames} \\cdot N_{atoms}} \\sum_i \\sum_j \\min\\left(\\|T_i^{-1} \\cdot x_j^{pred} - T_i^{-1} \\cdot x_j^{true}\\|, d_{clamp}\\right)$$\n",
    "\n",
    "Where:\n",
    "- $T_i$: Rigid transformation of frame $i$\n",
    "- $x_j$: Position of atom $j$\n",
    "- $d_{clamp}$: Clamping distance (10 Å for backbone, varies for sidechains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_inverse_frame(rotation, translation, points):\n",
    "    \"\"\"\n",
    "    Apply inverse rigid transformation: R^T @ (points - t)\n",
    "    \n",
    "    Args:\n",
    "        rotation: [N_frames, 3, 3] rotation matrices\n",
    "        translation: [N_frames, 3] translation vectors\n",
    "        points: [N_points, 3] points to transform\n",
    "    \n",
    "    Returns:\n",
    "        Transformed points [N_frames, N_points, 3]\n",
    "    \"\"\"\n",
    "    # Subtract translation: [N_points, 3] - [N_frames, 1, 3] -> [N_frames, N_points, 3]\n",
    "    centered = points[None, :, :] - translation[:, None, :]\n",
    "    \n",
    "    # Apply inverse rotation: R^T @ centered\n",
    "    # [N_frames, 3, 3]^T @ [N_frames, N_points, 3] -> [N_frames, N_points, 3]\n",
    "    return np.einsum('fji,fpj->fpi', rotation, centered)\n",
    "\n",
    "\n",
    "def compute_fape(\n",
    "    pred_frames_rot,      # [N_res, 3, 3] predicted frame rotations\n",
    "    pred_frames_trans,    # [N_res, 3] predicted frame translations\n",
    "    target_frames_rot,    # [N_res, 3, 3] ground truth frame rotations\n",
    "    target_frames_trans,  # [N_res, 3] ground truth frame translations\n",
    "    pred_positions,       # [N_atoms, 3] predicted atom positions\n",
    "    target_positions,     # [N_atoms, 3] ground truth atom positions\n",
    "    frames_mask,          # [N_res] mask for valid frames\n",
    "    positions_mask,       # [N_atoms] mask for valid atoms\n",
    "    length_scale=10.0,    # Scale factor for loss\n",
    "    l1_clamp_distance=10.0  # Clamping distance\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute Frame Aligned Point Error (FAPE).\n",
    "    \n",
    "    Algorithm 28 from AlphaFold2 supplementary materials.\n",
    "    \n",
    "    Args:\n",
    "        pred_frames_rot: Predicted frame rotations [N_res, 3, 3]\n",
    "        pred_frames_trans: Predicted frame translations [N_res, 3]\n",
    "        target_frames_rot: Ground truth frame rotations [N_res, 3, 3]\n",
    "        target_frames_trans: Ground truth frame translations [N_res, 3]\n",
    "        pred_positions: Predicted atom positions [N_atoms, 3]\n",
    "        target_positions: Ground truth atom positions [N_atoms, 3]\n",
    "        frames_mask: Mask for valid frames [N_res]\n",
    "        positions_mask: Mask for valid atoms [N_atoms]\n",
    "        length_scale: Scale factor for final loss\n",
    "        l1_clamp_distance: Maximum distance for clamping\n",
    "    \n",
    "    Returns:\n",
    "        FAPE loss (scalar)\n",
    "    \"\"\"\n",
    "    N_frames = pred_frames_rot.shape[0]\n",
    "    N_atoms = pred_positions.shape[0]\n",
    "    \n",
    "    print(f\"Computing FAPE: {N_frames} frames, {N_atoms} atoms\")\n",
    "    \n",
    "    # Step 1: Transform predicted positions to each predicted frame's local coordinates\n",
    "    # Line 1: For each frame i, compute T_i^{-1} @ x_j for all atoms j\n",
    "    pred_local = apply_inverse_frame(\n",
    "        pred_frames_rot, pred_frames_trans, pred_positions\n",
    "    )  # [N_frames, N_atoms, 3]\n",
    "    \n",
    "    print(f\"Predicted positions in local frames: {pred_local.shape}\")\n",
    "    \n",
    "    # Step 2: Transform target positions to each target frame's local coordinates\n",
    "    # Line 2: For each frame i, compute T_i^{-1} @ x_j^{true} for all atoms j\n",
    "    target_local = apply_inverse_frame(\n",
    "        target_frames_rot, target_frames_trans, target_positions\n",
    "    )  # [N_frames, N_atoms, 3]\n",
    "    \n",
    "    print(f\"Target positions in local frames: {target_local.shape}\")\n",
    "    \n",
    "    # Step 3: Compute distances between corresponding local positions\n",
    "    # Line 3: d_ij = ||pred_local_ij - target_local_ij||\n",
    "    distances = np.sqrt(\n",
    "        np.sum((pred_local - target_local) ** 2, axis=-1) + 1e-8\n",
    "    )  # [N_frames, N_atoms]\n",
    "    \n",
    "    print(f\"Distances: {distances.shape}\")\n",
    "    print(f\"  Mean distance: {distances.mean():.3f} Å\")\n",
    "    print(f\"  Max distance: {distances.max():.3f} Å\")\n",
    "    \n",
    "    # Step 4: Clamp distances (Line 4)\n",
    "    if l1_clamp_distance is not None:\n",
    "        distances = np.minimum(distances, l1_clamp_distance)\n",
    "        print(f\"  After clamping (max {l1_clamp_distance} Å): max = {distances.max():.3f} Å\")\n",
    "    \n",
    "    # Step 5: Apply masks\n",
    "    # Create combined mask: [N_frames, N_atoms]\n",
    "    mask = frames_mask[:, None] * positions_mask[None, :]\n",
    "    \n",
    "    # Step 6: Compute weighted average (Lines 5-6)\n",
    "    masked_distances = distances * mask\n",
    "    fape = np.sum(masked_distances) / (np.sum(mask) + 1e-8)\n",
    "    \n",
    "    # Scale by length_scale\n",
    "    fape = fape / length_scale\n",
    "    \n",
    "    print(f\"\\nFinal FAPE loss: {fape:.6f}\")\n",
    "    \n",
    "    return fape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "N_res = 20  # Number of residues (frames)\n",
    "N_atoms = N_res * 3  # 3 backbone atoms per residue (N, CA, C)\n",
    "\n",
    "# Generate \"ground truth\" structure - a simple helix\n",
    "def generate_helix(n_residues, rise_per_residue=1.5, radius=2.3, twist=100):\n",
    "    \"\"\"Generate an idealized alpha helix.\"\"\"\n",
    "    positions = []\n",
    "    frames_rot = []\n",
    "    frames_trans = []\n",
    "    \n",
    "    for i in range(n_residues):\n",
    "        angle = np.radians(twist * i)\n",
    "        z = rise_per_residue * i\n",
    "        \n",
    "        # CA position (on helix axis + radius)\n",
    "        ca = np.array([radius * np.cos(angle), radius * np.sin(angle), z])\n",
    "        \n",
    "        # N and C positions (simplified)\n",
    "        n = ca + np.array([-1.46, 0, -0.5])\n",
    "        c = ca + np.array([1.0, 0.5, 0.5])\n",
    "        \n",
    "        positions.extend([n, ca, c])\n",
    "        \n",
    "        # Simple frame (identity rotation, CA as translation)\n",
    "        frames_rot.append(np.eye(3))\n",
    "        frames_trans.append(ca)\n",
    "    \n",
    "    return np.array(positions), np.array(frames_rot), np.array(frames_trans)\n",
    "\n",
    "# Ground truth structure\n",
    "target_positions, target_frames_rot, target_frames_trans = generate_helix(N_res)\n",
    "\n",
    "print(f\"Ground truth structure:\")\n",
    "print(f\"  Positions: {target_positions.shape}\")\n",
    "print(f\"  Frames: {target_frames_rot.shape}, {target_frames_trans.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions with varying levels of error\n",
    "\n",
    "# Case 1: Perfect prediction (FAPE should be ~0)\n",
    "print(\"=\"*50)\n",
    "print(\"Case 1: Perfect prediction\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "pred_positions = target_positions.copy()\n",
    "pred_frames_rot = target_frames_rot.copy()\n",
    "pred_frames_trans = target_frames_trans.copy()\n",
    "\n",
    "frames_mask = np.ones(N_res)\n",
    "positions_mask = np.ones(N_atoms)\n",
    "\n",
    "fape_perfect = compute_fape(\n",
    "    pred_frames_rot, pred_frames_trans,\n",
    "    target_frames_rot, target_frames_trans,\n",
    "    pred_positions, target_positions,\n",
    "    frames_mask, positions_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2: Small random perturbation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Case 2: Small perturbation (0.5 Å noise)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "noise_scale = 0.5\n",
    "pred_positions = target_positions + np.random.randn(*target_positions.shape) * noise_scale\n",
    "pred_frames_trans = target_frames_trans + np.random.randn(*target_frames_trans.shape) * noise_scale\n",
    "\n",
    "fape_small = compute_fape(\n",
    "    pred_frames_rot, pred_frames_trans,\n",
    "    target_frames_rot, target_frames_trans,\n",
    "    pred_positions, target_positions,\n",
    "    frames_mask, positions_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 3: Larger perturbation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Case 3: Larger perturbation (2.0 Å noise)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "noise_scale = 2.0\n",
    "pred_positions = target_positions + np.random.randn(*target_positions.shape) * noise_scale\n",
    "pred_frames_trans = target_frames_trans + np.random.randn(*target_frames_trans.shape) * noise_scale\n",
    "\n",
    "fape_large = compute_fape(\n",
    "    pred_frames_rot, pred_frames_trans,\n",
    "    target_frames_rot, target_frames_trans,\n",
    "    pred_positions, target_positions,\n",
    "    frames_mask, positions_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 4: Very large errors (to test clamping)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Case 4: Large errors (20 Å noise) - tests clamping\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "noise_scale = 20.0\n",
    "pred_positions = target_positions + np.random.randn(*target_positions.shape) * noise_scale\n",
    "pred_frames_trans = target_frames_trans + np.random.randn(*target_frames_trans.shape) * noise_scale\n",
    "\n",
    "fape_clamped = compute_fape(\n",
    "    pred_frames_rot, pred_frames_trans,\n",
    "    target_frames_rot, target_frames_trans,\n",
    "    pred_positions, target_positions,\n",
    "    frames_mask, positions_mask,\n",
    "    l1_clamp_distance=10.0  # Clamp at 10 Å\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAPE Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FAPE Loss Summary\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Perfect prediction:     {fape_perfect:.6f}\")\n",
    "print(f\"Small noise (0.5 Å):    {fape_small:.6f}\")\n",
    "print(f\"Large noise (2.0 Å):    {fape_large:.6f}\")\n",
    "print(f\"Very large (clamped):   {fape_clamped:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SE(3) Invariance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAPE should be invariant to global rotation/translation\n",
    "\n",
    "# Apply random global transformation\n",
    "def random_rotation():\n",
    "    \"\"\"Generate random rotation matrix.\"\"\"\n",
    "    theta = np.random.randn(3) * 0.5\n",
    "    norm = np.linalg.norm(theta)\n",
    "    if norm < 1e-6:\n",
    "        return np.eye(3)\n",
    "    axis = theta / norm\n",
    "    K = np.array([[0, -axis[2], axis[1]],\n",
    "                  [axis[2], 0, -axis[0]],\n",
    "                  [-axis[1], axis[0], 0]])\n",
    "    return np.eye(3) + np.sin(norm) * K + (1 - np.cos(norm)) * K @ K\n",
    "\n",
    "global_rot = random_rotation()\n",
    "global_trans = np.random.randn(3) * 10\n",
    "\n",
    "# Transform predictions\n",
    "pred_positions_transformed = (global_rot @ pred_positions.T).T + global_trans\n",
    "pred_frames_trans_transformed = (global_rot @ pred_frames_trans.T).T + global_trans\n",
    "pred_frames_rot_transformed = np.array([global_rot @ r for r in pred_frames_rot])\n",
    "\n",
    "# Also transform targets\n",
    "target_positions_transformed = (global_rot @ target_positions.T).T + global_trans\n",
    "target_frames_trans_transformed = (global_rot @ target_frames_trans.T).T + global_trans\n",
    "target_frames_rot_transformed = np.array([global_rot @ r for r in target_frames_rot])\n",
    "\n",
    "print(\"Testing SE(3) invariance...\")\n",
    "print(f\"Applied rotation:\\n{global_rot}\")\n",
    "print(f\"Applied translation: {global_trans}\")\n",
    "\n",
    "fape_transformed = compute_fape(\n",
    "    pred_frames_rot_transformed, pred_frames_trans_transformed,\n",
    "    target_frames_rot_transformed, target_frames_trans_transformed,\n",
    "    pred_positions_transformed, target_positions_transformed,\n",
    "    frames_mask, positions_mask\n",
    ")\n",
    "\n",
    "print(f\"\\nOriginal FAPE:    {fape_clamped:.6f}\")\n",
    "print(f\"Transformed FAPE: {fape_transformed:.6f}\")\n",
    "print(f\"Difference: {abs(fape_clamped - fape_transformed):.9f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Reference\n",
    "\n",
    "```python\n",
    "# From AF2-source-code/model/all_atom.py\n",
    "\n",
    "def frame_aligned_point_error(\n",
    "    pred_frames: r3.Rigids,\n",
    "    target_frames: r3.Rigids,\n",
    "    frames_mask: jnp.ndarray,\n",
    "    pred_positions: r3.Vecs,\n",
    "    target_positions: r3.Vecs,\n",
    "    positions_mask: jnp.ndarray,\n",
    "    l1_clamp_distance: Optional[float] = None,\n",
    "    length_scale: float = 1.0,\n",
    ") -> jnp.ndarray:\n",
    "  \"\"\"Measure point error under different alignments.\n",
    "\n",
    "  Jumper et al. (2021) Suppl. Alg. 28 \"computeFAPE\"\n",
    "  \"\"\"\n",
    "  # Transform predicted and target positions to local frames\n",
    "  local_pred_pos = pred_frames.apply_inverse(pred_positions)\n",
    "  local_target_pos = target_frames.apply_inverse(target_positions)\n",
    "\n",
    "  # Compute L2 distance\n",
    "  error_dist = jnp.sqrt(\n",
    "      r3.vecs_squared_distance(local_pred_pos, local_target_pos) + 1e-8)\n",
    "\n",
    "  # Clamp\n",
    "  if l1_clamp_distance:\n",
    "    error_dist = jnp.minimum(error_dist, l1_clamp_distance)\n",
    "\n",
    "  # Normalize and return\n",
    "  return jnp.sum(error_dist * mask) / (jnp.sum(mask) + 1e-8) / length_scale\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **SE(3) Invariance**: FAPE is invariant to global rotation and translation because it computes errors in local frames.\n",
    "\n",
    "2. **All-to-All**: Each frame evaluates the error of ALL atoms, not just atoms in that residue. This captures long-range structure.\n",
    "\n",
    "3. **Clamping**: Distance clamping prevents outliers from dominating the loss. Default is 10 Å for backbone.\n",
    "\n",
    "4. **Scale Factor**: The length_scale (default 10 Å) normalizes the loss to a reasonable range."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
