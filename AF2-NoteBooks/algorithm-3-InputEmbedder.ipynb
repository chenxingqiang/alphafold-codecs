{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 3: Input Embedder\n",
    "\n",
    "The Input Embedder converts raw sequence and MSA features into initial representations for the Evoformer. It creates both the MSA representation (`m`) and pair representation (`z`).\n",
    "\n",
    "## Algorithm Pseudocode\n",
    "\n",
    "![Input Embedder](../imgs/algorithms/InputEmbedder.png)\n",
    "\n",
    "## Source Code Location\n",
    "- **File**: `AF2-source-code/model/modules.py`\n",
    "- **Class**: `EmbeddingsAndEvoformer`\n",
    "- **Lines**: 1673-1760 (embedding portion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The Input Embedder performs several key operations:\n",
    "\n",
    "1. **Target Features → 1D Embedding**: Embed target sequence features\n",
    "2. **MSA Features → MSA Embedding**: Embed MSA features\n",
    "3. **Pair Features**: Create initial pair representation from:\n",
    "   - Outer product of target embeddings (left × right)\n",
    "   - Relative position encoding (Algorithm 4)\n",
    "   - Previous structure (for recycling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Feature Description\n",
    "\n",
    "| Feature | Shape | Description |\n",
    "|---------|-------|-------------|\n",
    "| `target_feat` | [N_res, 22] | One-hot amino acid type + features |\n",
    "| `msa_feat` | [N_seq, N_res, 49] | MSA features (one-hot + deletion info) |\n",
    "| `residue_index` | [N_res] | Residue position indices |\n",
    "| `seq_mask` | [N_res] | Valid residue mask |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(indices, num_classes):\n",
    "    \"\"\"Create one-hot encoding.\"\"\"\n",
    "    return np.eye(num_classes)[indices]\n",
    "\n",
    "\n",
    "def relpos_encoding(residue_index, max_relative_feature=32):\n",
    "    \"\"\"\n",
    "    Relative position encoding (Algorithm 4 + Algorithm 5).\n",
    "    \n",
    "    Creates one-hot encoding of clipped relative positions.\n",
    "    \n",
    "    Args:\n",
    "        residue_index: [N_res] residue indices\n",
    "        max_relative_feature: Maximum relative distance to encode\n",
    "    \n",
    "    Returns:\n",
    "        rel_pos: [N_res, N_res, 2*max_relative_feature+1] one-hot encoding\n",
    "    \"\"\"\n",
    "    N_res = len(residue_index)\n",
    "    \n",
    "    # Compute pairwise position offsets\n",
    "    offset = residue_index[:, None] - residue_index[None, :]\n",
    "    \n",
    "    # Clip to [-max, max] and shift to [0, 2*max]\n",
    "    clipped = np.clip(offset + max_relative_feature, 0, 2 * max_relative_feature)\n",
    "    \n",
    "    # One-hot encode\n",
    "    rel_pos = one_hot(clipped.astype(int), 2 * max_relative_feature + 1)\n",
    "    \n",
    "    return rel_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_embedder(\n",
    "    target_feat,      # [N_res, d_target] target sequence features\n",
    "    msa_feat,         # [N_seq, N_res, d_msa] MSA features\n",
    "    residue_index,    # [N_res] residue indices\n",
    "    c_m=256,          # MSA channel dimension\n",
    "    c_z=128,          # Pair channel dimension\n",
    "    max_relative_feature=32  # Max relative position\n",
    "):\n",
    "    \"\"\"\n",
    "    Input Embedder - Algorithm 3.\n",
    "    \n",
    "    Embeds input features into initial MSA and pair representations.\n",
    "    \n",
    "    Args:\n",
    "        target_feat: Target sequence features [N_res, d_target]\n",
    "        msa_feat: MSA features [N_seq, N_res, d_msa]\n",
    "        residue_index: Residue position indices [N_res]\n",
    "        c_m: MSA channel dimension\n",
    "        c_z: Pair channel dimension\n",
    "        max_relative_feature: Maximum relative position to encode\n",
    "    \n",
    "    Returns:\n",
    "        msa_act: MSA representation [N_seq, N_res, c_m]\n",
    "        pair_act: Pair representation [N_res, N_res, c_z]\n",
    "    \"\"\"\n",
    "    N_res, d_target = target_feat.shape\n",
    "    N_seq, _, d_msa = msa_feat.shape\n",
    "    \n",
    "    print(f\"Input Embedder\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Target features: {target_feat.shape}\")\n",
    "    print(f\"MSA features: {msa_feat.shape}\")\n",
    "    print(f\"Residue indices: {residue_index.shape}\")\n",
    "    print()\n",
    "    \n",
    "    # ========== Step 1: Embed target sequence (Line 1) ==========\n",
    "    # Linear projection of target features\n",
    "    w_target = np.random.randn(d_target, c_m) * 0.01\n",
    "    preprocess_1d = target_feat @ w_target  # [N_res, c_m]\n",
    "    \n",
    "    print(f\"Step 1 - Target embedding: {preprocess_1d.shape}\")\n",
    "    \n",
    "    # ========== Step 2: Embed MSA (Line 2) ==========\n",
    "    # Linear projection of MSA features\n",
    "    w_msa = np.random.randn(d_msa, c_m) * 0.01\n",
    "    preprocess_msa = np.einsum('sra,ad->srd', msa_feat, w_msa)  # [N_seq, N_res, c_m]\n",
    "    \n",
    "    print(f\"Step 2 - MSA embedding: {preprocess_msa.shape}\")\n",
    "    \n",
    "    # ========== Step 3: Combine for MSA representation (Line 3) ==========\n",
    "    # Add target embedding (broadcasted) to MSA embedding\n",
    "    msa_act = preprocess_1d[None, :, :] + preprocess_msa  # [N_seq, N_res, c_m]\n",
    "    \n",
    "    print(f\"Step 3 - Combined MSA representation: {msa_act.shape}\")\n",
    "    \n",
    "    # ========== Step 4: Create pair representation (Lines 4-5) ==========\n",
    "    # Left projection\n",
    "    w_left = np.random.randn(d_target, c_z) * 0.01\n",
    "    left_single = target_feat @ w_left  # [N_res, c_z]\n",
    "    \n",
    "    # Right projection\n",
    "    w_right = np.random.randn(d_target, c_z) * 0.01\n",
    "    right_single = target_feat @ w_right  # [N_res, c_z]\n",
    "    \n",
    "    # Outer sum to create pair features\n",
    "    pair_act = left_single[:, None, :] + right_single[None, :, :]  # [N_res, N_res, c_z]\n",
    "    \n",
    "    print(f\"Step 4 - Initial pair representation: {pair_act.shape}\")\n",
    "    \n",
    "    # ========== Step 5: Add relative position encoding (Line 6) ==========\n",
    "    # Compute relative position features\n",
    "    rel_pos = relpos_encoding(residue_index, max_relative_feature)\n",
    "    \n",
    "    print(f\"Step 5 - Relative position encoding: {rel_pos.shape}\")\n",
    "    \n",
    "    # Project relative position to pair dimension\n",
    "    d_relpos = 2 * max_relative_feature + 1\n",
    "    w_relpos = np.random.randn(d_relpos, c_z) * 0.01\n",
    "    rel_pos_proj = np.einsum('ija,ad->ijd', rel_pos, w_relpos)  # [N_res, N_res, c_z]\n",
    "    \n",
    "    # Add to pair representation\n",
    "    pair_act = pair_act + rel_pos_proj\n",
    "    \n",
    "    print(f\"Step 5 - Pair with relpos: {pair_act.shape}\")\n",
    "    \n",
    "    return msa_act, pair_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "N_res = 64      # Number of residues\n",
    "N_seq = 128     # Number of MSA sequences\n",
    "d_target = 22   # Target feature dimension (21 amino acids + 1)\n",
    "d_msa = 49      # MSA feature dimension (23 amino acids + deletion features)\n",
    "\n",
    "# Create test inputs\n",
    "# Random amino acid sequence (one-hot encoded)\n",
    "aatype = np.random.randint(0, 21, size=N_res)\n",
    "target_feat = one_hot(aatype, d_target).astype(np.float32)\n",
    "\n",
    "# Random MSA (one-hot + features)\n",
    "msa_aatype = np.random.randint(0, 23, size=(N_seq, N_res))  # 23 = 21 AA + gap + mask\n",
    "msa_onehot = one_hot(msa_aatype, 23)\n",
    "msa_features = np.concatenate([\n",
    "    msa_onehot,\n",
    "    np.random.rand(N_seq, N_res, d_msa - 23)  # Additional features\n",
    "], axis=-1).astype(np.float32)\n",
    "\n",
    "# Residue indices\n",
    "residue_index = np.arange(N_res)\n",
    "\n",
    "print(f\"Test Input Summary\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"Sequence length: {N_res}\")\n",
    "print(f\"MSA depth: {N_seq}\")\n",
    "print(f\"Target features: {target_feat.shape}\")\n",
    "print(f\"MSA features: {msa_features.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run input embedder\n",
    "msa_act, pair_act = input_embedder(\n",
    "    target_feat,\n",
    "    msa_features,\n",
    "    residue_index,\n",
    "    c_m=256,\n",
    "    c_z=128,\n",
    "    max_relative_feature=32\n",
    ")\n",
    "\n",
    "print(f\"\\nOutput Summary\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"MSA representation: {msa_act.shape}\")\n",
    "print(f\"Pair representation: {pair_act.shape}\")\n",
    "print(f\"\\nMSA stats: mean={msa_act.mean():.4f}, std={msa_act.std():.4f}\")\n",
    "print(f\"Pair stats: mean={pair_act.mean():.4f}, std={pair_act.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Pair Representation Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pair representation should show structure from relative positions\n",
    "# Check the diagonal pattern from relpos encoding\n",
    "\n",
    "# Take first channel and look at structure\n",
    "pair_channel_0 = pair_act[:, :, 0]\n",
    "\n",
    "print(\"Pair representation structure (first channel):\")\n",
    "print(f\"  Diagonal mean: {np.diag(pair_channel_0).mean():.4f}\")\n",
    "print(f\"  Off-diagonal mean: {(pair_channel_0 - np.diag(np.diag(pair_channel_0))).mean():.4f}\")\n",
    "\n",
    "# Check symmetry\n",
    "asymmetry = np.abs(pair_channel_0 - pair_channel_0.T).mean()\n",
    "print(f\"  Asymmetry: {asymmetry:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Reference\n",
    "\n",
    "```python\n",
    "# From AF2-source-code/model/modules.py (EmbeddingsAndEvoformer.__call__)\n",
    "\n",
    "# Embed clustered MSA.\n",
    "# Jumper et al. (2021) Suppl. Alg. 2 \"Inference\" line 5\n",
    "# Jumper et al. (2021) Suppl. Alg. 3 \"InputEmbedder\"\n",
    "preprocess_1d = common_modules.Linear(\n",
    "    c.msa_channel, name='preprocess_1d')(batch['target_feat'])\n",
    "\n",
    "preprocess_msa = common_modules.Linear(\n",
    "    c.msa_channel, name='preprocess_msa')(batch['msa_feat'])\n",
    "\n",
    "msa_activations = jnp.expand_dims(preprocess_1d, axis=0) + preprocess_msa\n",
    "\n",
    "left_single = common_modules.Linear(\n",
    "    c.pair_channel, name='left_single')(batch['target_feat'])\n",
    "right_single = common_modules.Linear(\n",
    "    c.pair_channel, name='right_single')(batch['target_feat'])\n",
    "pair_activations = left_single[:, None] + right_single[None]\n",
    "\n",
    "# Relative position encoding\n",
    "# Jumper et al. (2021) Suppl. Alg. 4 \"relpos\"\n",
    "# Jumper et al. (2021) Suppl. Alg. 5 \"one_hot\"\n",
    "if c.max_relative_feature:\n",
    "    pos = batch['residue_index']\n",
    "    offset = pos[:, None] - pos[None, :]\n",
    "    rel_pos = jax.nn.one_hot(\n",
    "        jnp.clip(offset + c.max_relative_feature, 0, 2 * c.max_relative_feature),\n",
    "        2 * c.max_relative_feature + 1)\n",
    "    pair_activations += common_modules.Linear(\n",
    "        c.pair_channel, name='pair_activiations')(rel_pos)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Two Representations**: Creates both MSA (sequence-level) and pair (residue-pair-level) representations.\n",
    "\n",
    "2. **Target + MSA**: MSA representation combines target sequence info (broadcast) with MSA-specific features.\n",
    "\n",
    "3. **Outer Sum**: Pair representation starts as outer sum of left/right target projections.\n",
    "\n",
    "4. **Relative Position**: Position encoding is crucial for understanding sequence structure.\n",
    "\n",
    "5. **Linear Projections**: All embeddings use simple linear layers, complexity comes from downstream modules."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
