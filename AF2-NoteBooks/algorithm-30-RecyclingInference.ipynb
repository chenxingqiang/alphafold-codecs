{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 30: Recycling (Inference)\n",
    "\n",
    "During inference, AlphaFold2 recycles predictions multiple times to iteratively refine the structure. Each iteration uses the previous output as additional input, allowing the model to correct errors and improve predictions.\n",
    "\n",
    "## Algorithm Pseudocode\n",
    "\n",
    "![RecyclingInference](../imgs/algorithms/RecyclingInference.png)\n",
    "\n",
    "## Source Code Location\n",
    "- **File**: `AF2-source-code/model/modules.py`\n",
    "- **Class**: `AlphaFold`\n",
    "- **Lines**: 123-200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### Recycling Process\n",
    "\n",
    "```\n",
    "Iteration 0:\n",
    "├── prev_pos = zeros (no prior structure)\n",
    "├── prev_msa = zeros (no prior MSA embedding)\n",
    "├── prev_pair = zeros (no prior pair representation)\n",
    "└── Run model → output₀\n",
    "        ↓\n",
    "Iteration 1:\n",
    "├── prev_pos = output₀.positions\n",
    "├── prev_msa = output₀.msa_first_row\n",
    "├── prev_pair = output₀.pair_repr\n",
    "└── Run model → output₁\n",
    "        ↓\n",
    "    ... (repeat) ...\n",
    "        ↓\n",
    "Iteration N (final):\n",
    "└── Return output_N as final prediction\n",
    "```\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Fixed iterations**: Typically 3 recycling iterations during inference\n",
    "2. **No gradients**: All iterations use stop_gradient (inference only)\n",
    "3. **Same weights**: The same model is applied in each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgram_from_positions(pos, min_bin=3.25, max_bin=50.75, num_bins=15):\n",
    "    \"\"\"\n",
    "    Compute distance histogram from positions.\n",
    "    Used to convert previous positions to features.\n",
    "    \"\"\"\n",
    "    N_res = pos.shape[0]\n",
    "    \n",
    "    # Pairwise distances\n",
    "    diff = pos[:, None, :] - pos[None, :, :]\n",
    "    dist = np.sqrt(np.sum(diff**2, axis=-1) + 1e-8)\n",
    "    \n",
    "    # Bin edges\n",
    "    bins = np.linspace(min_bin, max_bin, num_bins + 1)\n",
    "    \n",
    "    # One-hot histogram\n",
    "    dgram = np.zeros((N_res, N_res, num_bins))\n",
    "    for i in range(num_bins):\n",
    "        mask = (dist >= bins[i]) & (dist < bins[i+1])\n",
    "        dgram[:, :, i] = mask.astype(float)\n",
    "    \n",
    "    return dgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel:\n",
    "    \"\"\"\n",
    "    Simplified AlphaFold-like model for demonstrating recycling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, c_m=256, c_z=128):\n",
    "        self.c_m = c_m\n",
    "        self.c_z = c_z\n",
    "    \n",
    "    def __call__(self, batch, prev, is_training=False):\n",
    "        \"\"\"\n",
    "        Single forward pass of the model.\n",
    "        \n",
    "        Args:\n",
    "            batch: Input features\n",
    "            prev: Previous iteration outputs\n",
    "            is_training: Training mode flag\n",
    "        \n",
    "        Returns:\n",
    "            Model outputs\n",
    "        \"\"\"\n",
    "        N_res = batch['aatype'].shape[0]\n",
    "        \n",
    "        # Simulate embedding + Evoformer\n",
    "        msa_repr = np.random.randn(1, N_res, self.c_m) * 0.1\n",
    "        pair_repr = np.random.randn(N_res, N_res, self.c_z) * 0.1\n",
    "        \n",
    "        # Add previous outputs (recycling embeddings)\n",
    "        if prev['prev_msa_first_row'] is not None:\n",
    "            msa_repr[0] = msa_repr[0] + prev['prev_msa_first_row']\n",
    "        \n",
    "        if prev['prev_pair'] is not None:\n",
    "            pair_repr = pair_repr + prev['prev_pair'] * 0.1\n",
    "        \n",
    "        if prev['prev_pos'] is not None:\n",
    "            # Add distance features from previous positions\n",
    "            ca_pos = prev['prev_pos'][:, 1, :]  # CA atoms\n",
    "            dgram = dgram_from_positions(ca_pos)\n",
    "            # Project and add (simplified)\n",
    "            pair_repr[:, :, :15] += dgram * 0.1\n",
    "        \n",
    "        # Simulate structure module\n",
    "        atom_positions = np.random.randn(N_res, 37, 3) * 5\n",
    "        if prev['prev_pos'] is not None:\n",
    "            # Refine from previous positions\n",
    "            atom_positions = prev['prev_pos'] + np.random.randn(N_res, 37, 3) * 0.5\n",
    "        \n",
    "        return {\n",
    "            'final_atom_positions': atom_positions,\n",
    "            'msa_first_row': msa_repr[0],\n",
    "            'pair_repr': pair_repr,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recycling_inference(batch, model, num_recycle=3):\n",
    "    \"\"\"\n",
    "    Recycling Inference - Algorithm 30.\n",
    "    \n",
    "    Iteratively refines predictions using recycling.\n",
    "    \n",
    "    Args:\n",
    "        batch: Input features\n",
    "        model: Model to run\n",
    "        num_recycle: Number of recycling iterations\n",
    "    \n",
    "    Returns:\n",
    "        Final prediction\n",
    "    \"\"\"\n",
    "    N_res = batch['aatype'].shape[0]\n",
    "    \n",
    "    print(f\"Recycling Inference\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Residues: {N_res}\")\n",
    "    print(f\"Recycle iterations: {num_recycle}\")\n",
    "    \n",
    "    # Initialize previous outputs (zeros for first iteration)\n",
    "    prev = {\n",
    "        'prev_pos': None,\n",
    "        'prev_msa_first_row': None,\n",
    "        'prev_pair': None,\n",
    "    }\n",
    "    \n",
    "    outputs_history = []\n",
    "    \n",
    "    # Recycling loop\n",
    "    for i in range(num_recycle + 1):\n",
    "        is_final = (i == num_recycle)\n",
    "        \n",
    "        print(f\"\\nIteration {i} {'(final)' if is_final else ''}:\")\n",
    "        \n",
    "        # Run model\n",
    "        output = model(batch, prev, is_training=False)\n",
    "        \n",
    "        # Track metrics\n",
    "        pos = output['final_atom_positions']\n",
    "        ca_pos = pos[:, 1, :]  # CA atoms\n",
    "        \n",
    "        # Compute some metrics\n",
    "        if len(outputs_history) > 0:\n",
    "            prev_ca = outputs_history[-1]['final_atom_positions'][:, 1, :]\n",
    "            rmsd = np.sqrt(np.mean((ca_pos - prev_ca) ** 2))\n",
    "            print(f\"  RMSD from previous: {rmsd:.4f}Å\")\n",
    "        \n",
    "        # Compute CA-CA distances for structure check\n",
    "        ca_dist = np.linalg.norm(np.diff(ca_pos, axis=0), axis=1)\n",
    "        print(f\"  Mean CA-CA distance: {ca_dist.mean():.2f}Å (std={ca_dist.std():.2f})\")\n",
    "        \n",
    "        outputs_history.append(output)\n",
    "        \n",
    "        # Update prev for next iteration (if not final)\n",
    "        if not is_final:\n",
    "            prev['prev_pos'] = output['final_atom_positions'].copy()\n",
    "            prev['prev_msa_first_row'] = output['msa_first_row'].copy()\n",
    "            prev['prev_pair'] = output['pair_repr'].copy()\n",
    "    \n",
    "    print(f\"\\nFinal output:\")\n",
    "    print(f\"  Atom positions: {output['final_atom_positions'].shape}\")\n",
    "    \n",
    "    return output, outputs_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Basic functionality\n",
    "print(\"Test 1: Basic Functionality\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "batch = {\n",
    "    'aatype': np.random.randint(0, 20, size=64),\n",
    "}\n",
    "\n",
    "model = SimpleModel(c_m=256, c_z=128)\n",
    "output, history = recycling_inference(batch, model, num_recycle=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Effect of recycling on structure convergence\n",
    "print(\"\\nTest 2: Structure Convergence with Recycling\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "batch = {'aatype': np.random.randint(0, 20, size=32)}\n",
    "model = SimpleModel()\n",
    "\n",
    "# Run with different numbers of recycles\n",
    "for n_recycle in [0, 1, 2, 3, 5]:\n",
    "    np.random.seed(42)  # Reset for consistency\n",
    "    output, history = recycling_inference(batch, model, num_recycle=n_recycle)\n",
    "    \n",
    "    # Compute final structure metrics\n",
    "    ca_pos = output['final_atom_positions'][:, 1, :]\n",
    "    radius_of_gyration = np.sqrt(np.mean(np.sum((ca_pos - ca_pos.mean(axis=0)) ** 2, axis=1)))\n",
    "    \n",
    "    print(f\"\\nRecycles={n_recycle}: Radius of gyration = {radius_of_gyration:.2f}Å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Track RMSD convergence\n",
    "print(\"\\nTest 3: RMSD Convergence Across Iterations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "batch = {'aatype': np.random.randint(0, 20, size=48)}\n",
    "model = SimpleModel()\n",
    "\n",
    "output, history = recycling_inference(batch, model, num_recycle=5)\n",
    "\n",
    "print(f\"\\nIteration-by-iteration analysis:\")\n",
    "for i in range(1, len(history)):\n",
    "    ca_prev = history[i-1]['final_atom_positions'][:, 1, :]\n",
    "    ca_curr = history[i]['final_atom_positions'][:, 1, :]\n",
    "    rmsd = np.sqrt(np.mean((ca_curr - ca_prev) ** 2))\n",
    "    print(f\"  Iteration {i-1} -> {i}: RMSD = {rmsd:.4f}Å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification: Key Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verification: Key Properties\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "batch = {'aatype': np.random.randint(0, 20, size=32)}\n",
    "model = SimpleModel()\n",
    "\n",
    "output, history = recycling_inference(batch, model, num_recycle=3)\n",
    "\n",
    "# Property 1: Correct number of iterations\n",
    "n_iterations = len(history)\n",
    "expected = 4  # num_recycle + 1\n",
    "print(f\"Property 1 - Correct iterations: {n_iterations == expected} ({n_iterations})\")\n",
    "\n",
    "# Property 2: Final output has correct shape\n",
    "N_res = batch['aatype'].shape[0]\n",
    "shape_correct = output['final_atom_positions'].shape == (N_res, 37, 3)\n",
    "print(f\"Property 2 - Output shape correct: {shape_correct}\")\n",
    "\n",
    "# Property 3: All outputs are finite\n",
    "all_finite = all(np.isfinite(h['final_atom_positions']).all() for h in history)\n",
    "print(f\"Property 3 - All outputs finite: {all_finite}\")\n",
    "\n",
    "# Property 4: Recycling uses previous output\n",
    "# Check that iteration 1 output differs from iteration 0\n",
    "pos_0 = history[0]['final_atom_positions']\n",
    "pos_1 = history[1]['final_atom_positions']\n",
    "differs = not np.allclose(pos_0, pos_1)\n",
    "print(f\"Property 4 - Iterations differ: {differs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Reference\n",
    "\n",
    "```python\n",
    "# From AF2-source-code/model/modules.py\n",
    "\n",
    "class AlphaFold(hk.Module):\n",
    "  \"\"\"AlphaFold model with recycling.\n",
    "\n",
    "  Jumper et al. (2021) Suppl. Alg. 30 \"RecyclingInference\"\n",
    "  Jumper et al. (2021) Suppl. Alg. 2 \"Inference\"\n",
    "  \"\"\"\n",
    "\n",
    "  def __call__(self, batch, is_training, ...):\n",
    "    impl = AlphaFoldIteration(self.config, self.global_config)\n",
    "    \n",
    "    # Initialize previous outputs\n",
    "    prev = {\n",
    "        'prev_pos': jnp.zeros([num_res, 37, 3]),\n",
    "        'prev_msa_first_row': jnp.zeros([num_res, msa_channel]),\n",
    "        'prev_pair': jnp.zeros([num_res, num_res, pair_channel]),\n",
    "    }\n",
    "    \n",
    "    # Recycling loop\n",
    "    for recycle_idx in range(num_recycle + 1):\n",
    "      # stop_gradient on previous outputs during inference\n",
    "      prev = jax.tree_map(jax.lax.stop_gradient, prev)\n",
    "      \n",
    "      # Run iteration\n",
    "      ret = impl(batch, prev, is_training=False, ...)\n",
    "      \n",
    "      # Extract outputs for next iteration\n",
    "      prev = {\n",
    "          'prev_pos': ret['structure_module']['final_atom_positions'],\n",
    "          'prev_msa_first_row': ret['representations']['msa_first_row'],\n",
    "          'prev_pair': ret['representations']['pair'],\n",
    "      }\n",
    "    \n",
    "    return ret\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Iterative Refinement**: Recycling allows the model to iteratively refine predictions, correcting errors from earlier iterations.\n",
    "\n",
    "2. **Three Recycled Tensors**:\n",
    "   - `prev_pos`: Previous atom positions (converted to distance features)\n",
    "   - `prev_msa_first_row`: Previous MSA representation (adds to MSA embedding)\n",
    "   - `prev_pair`: Previous pair representation (adds to pair features)\n",
    "\n",
    "3. **Fixed Iterations**: During inference, a fixed number of iterations (typically 3) is used.\n",
    "\n",
    "4. **No Gradients**: All recycled tensors have stop_gradient applied, so the model treats them as fixed inputs.\n",
    "\n",
    "5. **Same Weights**: The same model weights are used in each iteration - this is weight sharing across iterations.\n",
    "\n",
    "6. **Convergence**: In practice, predictions typically converge after 2-3 iterations, with diminishing returns beyond that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
