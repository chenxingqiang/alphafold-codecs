{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 29: predictPerResidueLDDT (pLDDT)\n",
    "\n",
    "pLDDT (predicted Local Distance Difference Test) is AlphaFold2's confidence metric. It predicts how accurate each residue's predicted position is, based on local distance comparisons.\n",
    "\n",
    "## Algorithm Pseudocode\n",
    "\n",
    "![predictPerResidueLDDT](../imgs/algorithms/predictPerResidueLDDT_Ca.png)\n",
    "\n",
    "## Source Code Location\n",
    "- **File**: `AF2-source-code/model/modules.py`\n",
    "- **Class**: `PredictedLDDTHead`\n",
    "- **Lines**: 999-1100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is LDDT?\n",
    "\n",
    "LDDT (Local Distance Difference Test) measures the fraction of local distances that are preserved between predicted and ground truth structures:\n",
    "\n",
    "$$\\text{LDDT} = \\frac{1}{|S|} \\sum_{i \\in S} \\frac{1}{4} \\sum_{t \\in \\{0.5, 1, 2, 4\\}} \\mathbb{1}[|d_{pred} - d_{true}| < t]$$\n",
    "\n",
    "Where:\n",
    "- $S$ = set of residue pairs within 15 Å\n",
    "- $d_{pred}, d_{true}$ = predicted and true CA-CA distances\n",
    "- $t$ = distance threshold (0.5, 1, 2, 4 Å)\n",
    "\n",
    "pLDDT predicts this value for each residue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(x, axis=-1, eps=1e-5):\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    var = np.var(x, axis=axis, keepdims=True)\n",
    "    return (x - mean) / np.sqrt(var + eps)\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    x_max = np.max(x, axis=axis, keepdims=True)\n",
    "    exp_x = np.exp(x - x_max)\n",
    "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "def predict_lddt(structure_module_output, num_bins=50, num_channels=128):\n",
    "    \"\"\"\n",
    "    Predict per-residue LDDT scores.\n",
    "    \n",
    "    Algorithm 29 from AlphaFold2 supplementary materials.\n",
    "    \n",
    "    Args:\n",
    "        structure_module_output: Final single representation from structure module [N_res, c_s]\n",
    "        num_bins: Number of LDDT bins (default 50, representing 0-1 in 0.02 increments)\n",
    "        num_channels: Hidden layer width\n",
    "    \n",
    "    Returns:\n",
    "        plddt_logits: [N_res, num_bins] logits for each LDDT bin\n",
    "        plddt_scores: [N_res] predicted LDDT scores (0-100 scale)\n",
    "    \"\"\"\n",
    "    N_res, c_s = structure_module_output.shape\n",
    "    \n",
    "    print(f\"pLDDT Prediction\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Input: {structure_module_output.shape}\")\n",
    "    \n",
    "    act = structure_module_output\n",
    "    \n",
    "    # Step 1: Layer normalization\n",
    "    act = layer_norm(act, axis=-1)\n",
    "    \n",
    "    # Step 2: First linear + ReLU\n",
    "    w1 = np.random.randn(c_s, num_channels) * np.sqrt(2.0 / c_s)\n",
    "    b1 = np.zeros(num_channels)\n",
    "    act = relu(act @ w1 + b1)\n",
    "    \n",
    "    print(f\"After first layer: {act.shape}\")\n",
    "    \n",
    "    # Step 3: Second linear + ReLU\n",
    "    w2 = np.random.randn(num_channels, num_channels) * np.sqrt(2.0 / num_channels)\n",
    "    b2 = np.zeros(num_channels)\n",
    "    act = relu(act @ w2 + b2)\n",
    "    \n",
    "    print(f\"After second layer: {act.shape}\")\n",
    "    \n",
    "    # Step 4: Final linear to bin logits\n",
    "    w3 = np.random.randn(num_channels, num_bins) * 0.01\n",
    "    b3 = np.zeros(num_bins)\n",
    "    logits = act @ w3 + b3\n",
    "    \n",
    "    print(f\"Logits: {logits.shape}\")\n",
    "    \n",
    "    # Step 5: Convert logits to scores\n",
    "    # Softmax over bins, then compute expected LDDT\n",
    "    probs = softmax(logits, axis=-1)\n",
    "    \n",
    "    # Bin centers (0.5/50 to 49.5/50, then scale to 0-100)\n",
    "    bin_centers = (np.arange(num_bins) + 0.5) / num_bins * 100\n",
    "    \n",
    "    # Expected LDDT per residue\n",
    "    plddt_scores = np.sum(probs * bin_centers, axis=-1)\n",
    "    \n",
    "    print(f\"pLDDT scores: {plddt_scores.shape}\")\n",
    "    print(f\"Score range: [{plddt_scores.min():.1f}, {plddt_scores.max():.1f}]\")\n",
    "    \n",
    "    return logits, plddt_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "N_res = 100\n",
    "c_s = 384  # Structure module output dimension\n",
    "\n",
    "# Create test input (simulating structure module output)\n",
    "structure_output = np.random.randn(N_res, c_s).astype(np.float32)\n",
    "\n",
    "print(f\"Input shape: {structure_output.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict pLDDT\n",
    "logits, plddt_scores = predict_lddt(\n",
    "    structure_output,\n",
    "    num_bins=50,\n",
    "    num_channels=128\n",
    ")\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Mean pLDDT: {plddt_scores.mean():.1f}\")\n",
    "print(f\"  Std pLDDT: {plddt_scores.std():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pLDDT Score Interpretation\n",
    "\n",
    "AlphaFold2 color-codes structures by pLDDT:\n",
    "\n",
    "| Score Range | Color | Interpretation |\n",
    "|-------------|-------|----------------|\n",
    "| > 90 | Blue | Very high confidence |\n",
    "| 70-90 | Cyan | Confident |\n",
    "| 50-70 | Yellow | Low confidence |\n",
    "| < 50 | Orange | Very low confidence |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize scores\n",
    "def categorize_plddt(scores):\n",
    "    categories = np.zeros(len(scores), dtype=int)\n",
    "    categories[scores >= 90] = 3  # Very high\n",
    "    categories[(scores >= 70) & (scores < 90)] = 2  # Confident\n",
    "    categories[(scores >= 50) & (scores < 70)] = 1  # Low\n",
    "    categories[scores < 50] = 0  # Very low\n",
    "    return categories\n",
    "\n",
    "categories = categorize_plddt(plddt_scores)\n",
    "\n",
    "print(\"pLDDT Category Distribution:\")\n",
    "print(f\"  Very high (>90): {np.sum(categories == 3)} residues\")\n",
    "print(f\"  Confident (70-90): {np.sum(categories == 2)} residues\")\n",
    "print(f\"  Low (50-70): {np.sum(categories == 1)} residues\")\n",
    "print(f\"  Very low (<50): {np.sum(categories == 0)} residues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Actual LDDT (for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lddt(pred_ca, true_ca, mask, cutoff=15.0):\n",
    "    \"\"\"\n",
    "    Compute actual LDDT scores for training supervision.\n",
    "    \n",
    "    Args:\n",
    "        pred_ca: Predicted CA positions [N_res, 3]\n",
    "        true_ca: Ground truth CA positions [N_res, 3]\n",
    "        mask: Residue mask [N_res]\n",
    "        cutoff: Distance cutoff for including pairs (default 15 Å)\n",
    "    \n",
    "    Returns:\n",
    "        lddt: Per-residue LDDT scores [N_res]\n",
    "    \"\"\"\n",
    "    N_res = len(pred_ca)\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    pred_dist = np.sqrt(np.sum((pred_ca[:, None] - pred_ca[None, :]) ** 2, axis=-1))\n",
    "    true_dist = np.sqrt(np.sum((true_ca[:, None] - true_ca[None, :]) ** 2, axis=-1))\n",
    "    \n",
    "    # Distance difference\n",
    "    diff = np.abs(pred_dist - true_dist)\n",
    "    \n",
    "    # Include pairs within cutoff (based on true structure)\n",
    "    include_mask = (true_dist < cutoff) & (mask[:, None] * mask[None, :] > 0)\n",
    "    np.fill_diagonal(include_mask, False)  # Exclude self\n",
    "    \n",
    "    # LDDT thresholds\n",
    "    thresholds = [0.5, 1.0, 2.0, 4.0]\n",
    "    \n",
    "    # Compute LDDT per residue\n",
    "    lddt = np.zeros(N_res)\n",
    "    for i in range(N_res):\n",
    "        if np.sum(include_mask[i]) == 0:\n",
    "            lddt[i] = 0\n",
    "            continue\n",
    "        \n",
    "        scores = []\n",
    "        for t in thresholds:\n",
    "            preserved = diff[i, include_mask[i]] < t\n",
    "            scores.append(np.mean(preserved))\n",
    "        lddt[i] = np.mean(scores)\n",
    "    \n",
    "    return lddt * 100  # Scale to 0-100\n",
    "\n",
    "\n",
    "# Test with synthetic data\n",
    "true_ca = np.random.randn(N_res, 3) * 10  # Random ground truth\n",
    "pred_ca = true_ca + np.random.randn(N_res, 3) * 1.5  # Prediction with noise\n",
    "mask = np.ones(N_res)\n",
    "\n",
    "actual_lddt = compute_lddt(pred_ca, true_ca, mask)\n",
    "\n",
    "print(f\"Actual LDDT scores:\")\n",
    "print(f\"  Mean: {actual_lddt.mean():.1f}\")\n",
    "print(f\"  Range: [{actual_lddt.min():.1f}, {actual_lddt.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Reference\n",
    "\n",
    "```python\n",
    "# From AF2-source-code/model/modules.py\n",
    "\n",
    "class PredictedLDDTHead(hk.Module):\n",
    "  \"\"\"Head to predict the per-residue LDDT to be used as a confidence measure.\n",
    "\n",
    "  Jumper et al. (2021) Suppl. Sec. 1.9.6 \"Model confidence prediction (pLDDT)\"\n",
    "  Jumper et al. (2021) Suppl. Alg. 29 \"predictPerResidueLDDT_Ca\"\n",
    "  \"\"\"\n",
    "\n",
    "  def __call__(self, representations, batch, is_training):\n",
    "    act = representations['structure_module']\n",
    "\n",
    "    act = hk.LayerNorm(axis=[-1], ...)(act)\n",
    "\n",
    "    act = common_modules.Linear(self.config.num_channels, initializer='relu')(act)\n",
    "    act = jax.nn.relu(act)\n",
    "\n",
    "    act = common_modules.Linear(self.config.num_channels, initializer='relu')(act)\n",
    "    act = jax.nn.relu(act)\n",
    "\n",
    "    logits = common_modules.Linear(self.config.num_bins, ...)(act)\n",
    "    return dict(logits=logits)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Simple Architecture**: Just LayerNorm + 2-layer MLP + linear output.\n",
    "\n",
    "2. **Binned Output**: Predicts distribution over LDDT bins, not direct values.\n",
    "\n",
    "3. **Input**: Uses final representation from Structure Module (single representation).\n",
    "\n",
    "4. **Training Target**: Actual LDDT computed from predicted vs. ground truth CA positions.\n",
    "\n",
    "5. **Scale**: Output is 0-100 (percentage of preserved distances)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
