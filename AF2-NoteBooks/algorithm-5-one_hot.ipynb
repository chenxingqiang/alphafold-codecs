{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 5: One-Hot Encoding\n",
    "\n",
    "One-hot encoding converts categorical indices to binary vectors. This fundamental operation is used throughout AlphaFold2 for encoding amino acid types, relative positions, and other discrete features.\n",
    "\n",
    "## Algorithm Pseudocode\n",
    "\n",
    "![one_hot](../imgs/algorithms/one_hot.png)\n",
    "\n",
    "## Source Code Location\n",
    "- **File**: `AF2-source-code/model/modules.py`\n",
    "- **Usage**: Throughout, via `jax.nn.one_hot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "One-hot encoding transforms integer indices into binary vectors:\n",
    "\n",
    "```\n",
    "Index 0 with 5 classes → [1, 0, 0, 0, 0]\n",
    "Index 2 with 5 classes → [0, 0, 1, 0, 0]\n",
    "Index 4 with 5 classes → [0, 0, 0, 0, 1]\n",
    "```\n",
    "\n",
    "### Usage in AlphaFold2\n",
    "\n",
    "| Feature | Classes | Description |\n",
    "|---------|---------|-------------|\n",
    "| Amino acid type | 20-21 | Standard amino acids (+ unknown) |\n",
    "| MSA amino acid | 23 | 20 AA + gap + mask + unknown |\n",
    "| Relative position | 65 | -32 to +32 relative positions |\n",
    "| Distance bins | 64 | For distogram predictions |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(indices, num_classes, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    One-Hot Encoding - Algorithm 5.\n",
    "    \n",
    "    Converts integer indices to one-hot vectors.\n",
    "    \n",
    "    Args:\n",
    "        indices: Integer array of any shape\n",
    "        num_classes: Number of classes (length of one-hot vector)\n",
    "        dtype: Output data type (default: float32)\n",
    "    \n",
    "    Returns:\n",
    "        One-hot encoded array with shape [..., num_classes]\n",
    "    \"\"\"\n",
    "    # Efficient implementation using identity matrix indexing\n",
    "    eye = np.eye(num_classes, dtype=dtype)\n",
    "    return eye[indices]\n",
    "\n",
    "\n",
    "def one_hot_explicit(indices, num_classes, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Explicit implementation showing the algorithm step-by-step.\n",
    "    \n",
    "    This version is clearer about what one-hot encoding does.\n",
    "    \"\"\"\n",
    "    # Create output array\n",
    "    output_shape = indices.shape + (num_classes,)\n",
    "    output = np.zeros(output_shape, dtype=dtype)\n",
    "    \n",
    "    # Flatten for easier indexing\n",
    "    flat_indices = indices.flatten()\n",
    "    flat_output = output.reshape(-1, num_classes)\n",
    "    \n",
    "    # Set 1s at appropriate positions\n",
    "    # For each position i, set output[i, indices[i]] = 1\n",
    "    flat_output[np.arange(len(flat_indices)), flat_indices] = 1.0\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def one_hot_with_mask(indices, num_classes, mask=None, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    One-hot encoding with optional masking.\n",
    "    \n",
    "    Masked positions get zero vectors.\n",
    "    \n",
    "    Args:\n",
    "        indices: Integer indices\n",
    "        num_classes: Number of classes\n",
    "        mask: Boolean mask (True = valid, False = masked)\n",
    "        dtype: Output data type\n",
    "    \n",
    "    Returns:\n",
    "        One-hot encoded array with masked positions zeroed\n",
    "    \"\"\"\n",
    "    onehot = one_hot(indices, num_classes, dtype)\n",
    "    \n",
    "    if mask is not None:\n",
    "        # Expand mask to match one-hot dimensions\n",
    "        mask_expanded = mask[..., None].astype(dtype)\n",
    "        onehot = onehot * mask_expanded\n",
    "    \n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Basic one-hot encoding\n",
    "print(\"Test 1: Basic One-Hot Encoding\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "indices = np.array([0, 1, 2, 3, 4])\n",
    "num_classes = 5\n",
    "\n",
    "onehot = one_hot(indices, num_classes)\n",
    "\n",
    "print(f\"Input indices: {indices}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Output shape: {onehot.shape}\")\n",
    "print(f\"\\nOne-hot matrix:\")\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Amino acid encoding\n",
    "print(\"\\nTest 2: Amino Acid Encoding\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Amino acid indices (0-19 for standard amino acids)\n",
    "AA_NAMES = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I',\n",
    "            'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "\n",
    "# Example sequence: \"ACDEF\"\n",
    "aa_indices = np.array([0, 4, 3, 6, 13])  # A, C, D, E, F\n",
    "\n",
    "aa_onehot = one_hot(aa_indices, num_classes=20)\n",
    "\n",
    "print(f\"Sequence: {[AA_NAMES[i] for i in aa_indices]}\")\n",
    "print(f\"Indices: {aa_indices}\")\n",
    "print(f\"One-hot shape: {aa_onehot.shape}\")\n",
    "\n",
    "# Verify we can recover the original indices\n",
    "recovered = np.argmax(aa_onehot, axis=-1)\n",
    "print(f\"Recovered indices: {recovered}\")\n",
    "print(f\"Recovery correct: {np.array_equal(aa_indices, recovered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: 2D input (MSA)\n",
    "print(\"\\nTest 3: MSA One-Hot Encoding\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "N_seq, N_res = 4, 8\n",
    "num_aa_classes = 23  # 20 AA + gap + mask + unknown\n",
    "\n",
    "# Random MSA\n",
    "msa = np.random.randint(0, num_aa_classes, size=(N_seq, N_res))\n",
    "\n",
    "msa_onehot = one_hot(msa, num_aa_classes)\n",
    "\n",
    "print(f\"MSA shape: {msa.shape}\")\n",
    "print(f\"MSA one-hot shape: {msa_onehot.shape}\")\n",
    "print(f\"Expected: ({N_seq}, {N_res}, {num_aa_classes})\")\n",
    "\n",
    "# Verify sum along last axis equals 1\n",
    "sums = msa_onehot.sum(axis=-1)\n",
    "print(f\"\\nAll rows sum to 1: {np.allclose(sums, 1.0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: With masking\n",
    "print(\"\\nTest 4: One-Hot with Masking\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "indices = np.array([0, 1, 2, 3, 4])\n",
    "mask = np.array([True, True, False, True, False])  # Mask positions 2 and 4\n",
    "\n",
    "onehot_masked = one_hot_with_mask(indices, num_classes=5, mask=mask)\n",
    "\n",
    "print(f\"Indices: {indices}\")\n",
    "print(f\"Mask: {mask}\")\n",
    "print(f\"\\nMasked one-hot:\")\n",
    "print(onehot_masked)\n",
    "print(f\"\\nMasked positions are zero vectors: {onehot_masked[2].sum() == 0 and onehot_masked[4].sum() == 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Compare implementations\n",
    "print(\"\\nTest 5: Compare Implementations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "indices = np.random.randint(0, 20, size=(100, 64))\n",
    "\n",
    "result1 = one_hot(indices, 20)\n",
    "result2 = one_hot_explicit(indices, 20)\n",
    "\n",
    "print(f\"Efficient implementation shape: {result1.shape}\")\n",
    "print(f\"Explicit implementation shape: {result2.shape}\")\n",
    "print(f\"Results match: {np.allclose(result1, result2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6: Relative position one-hot (as used in Algorithm 4)\n",
    "print(\"\\nTest 6: Relative Position One-Hot\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "max_relative = 32\n",
    "num_classes = 2 * max_relative + 1  # 65 classes\n",
    "\n",
    "# Simulate clipped and shifted relative positions\n",
    "offsets = np.array([-50, -32, -10, 0, 10, 32, 50])  # Various offsets\n",
    "clipped = np.clip(offsets, -max_relative, max_relative)\n",
    "shifted = clipped + max_relative  # Now in [0, 64]\n",
    "\n",
    "rel_onehot = one_hot(shifted, num_classes)\n",
    "\n",
    "print(f\"Original offsets: {offsets}\")\n",
    "print(f\"Clipped: {clipped}\")\n",
    "print(f\"Shifted (indices): {shifted}\")\n",
    "print(f\"\\nOne-hot peaks at: {np.argmax(rel_onehot, axis=-1)}\")\n",
    "print(f\"Shape: {rel_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification: Key Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verification: Key Properties\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "indices = np.random.randint(0, 20, size=(32, 64))\n",
    "onehot = one_hot(indices, 20)\n",
    "\n",
    "# Property 1: Binary values (0 or 1)\n",
    "is_binary = np.all((onehot == 0) | (onehot == 1))\n",
    "print(f\"Property 1 - Binary values: {is_binary}\")\n",
    "\n",
    "# Property 2: Exactly one 1 per vector\n",
    "row_sums = onehot.sum(axis=-1)\n",
    "is_valid_onehot = np.allclose(row_sums, 1.0)\n",
    "print(f\"Property 2 - Exactly one 1 per vector: {is_valid_onehot}\")\n",
    "\n",
    "# Property 3: Correct shape\n",
    "expected_shape = indices.shape + (20,)\n",
    "shape_correct = onehot.shape == expected_shape\n",
    "print(f\"Property 3 - Shape [..., num_classes]: {shape_correct}\")\n",
    "\n",
    "# Property 4: Invertible via argmax\n",
    "recovered = np.argmax(onehot, axis=-1)\n",
    "invertible = np.array_equal(indices, recovered)\n",
    "print(f\"Property 4 - Invertible via argmax: {invertible}\")\n",
    "\n",
    "# Property 5: Correct dtype\n",
    "dtype_correct = onehot.dtype == np.float32\n",
    "print(f\"Property 5 - Float32 dtype: {dtype_correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Performance Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Large input\n",
    "indices = np.random.randint(0, 20, size=(128, 256))\n",
    "n_runs = 100\n",
    "\n",
    "# Efficient implementation\n",
    "start = time.time()\n",
    "for _ in range(n_runs):\n",
    "    _ = one_hot(indices, 20)\n",
    "efficient_time = (time.time() - start) / n_runs * 1000\n",
    "\n",
    "# Explicit implementation\n",
    "start = time.time()\n",
    "for _ in range(n_runs):\n",
    "    _ = one_hot_explicit(indices, 20)\n",
    "explicit_time = (time.time() - start) / n_runs * 1000\n",
    "\n",
    "print(f\"Input shape: {indices.shape}\")\n",
    "print(f\"Number of runs: {n_runs}\")\n",
    "print(f\"\\nEfficient (eye indexing): {efficient_time:.3f} ms\")\n",
    "print(f\"Explicit (manual setting): {explicit_time:.3f} ms\")\n",
    "print(f\"Speedup: {explicit_time / efficient_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Reference\n",
    "\n",
    "```python\n",
    "# JAX implementation used in AlphaFold2\n",
    "import jax.nn\n",
    "\n",
    "# One-hot encoding in JAX\n",
    "onehot = jax.nn.one_hot(indices, num_classes)\n",
    "\n",
    "# Usage examples in AlphaFold2:\n",
    "\n",
    "# 1. Amino acid encoding (in data preprocessing)\n",
    "aatype_onehot = jax.nn.one_hot(batch['aatype'], 21)\n",
    "\n",
    "# 2. Relative position encoding (Algorithm 4)\n",
    "rel_pos = jax.nn.one_hot(\n",
    "    jnp.clip(offset + max_relative, 0, 2 * max_relative),\n",
    "    2 * max_relative + 1\n",
    ")\n",
    "\n",
    "# 3. Distance binning for distogram\n",
    "dgram = jax.nn.one_hot(distance_bins, num_bins)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Fundamental Operation**: One-hot encoding is one of the most basic but essential operations in neural networks for handling categorical data.\n",
    "\n",
    "2. **Memory Trade-off**: One-hot encoding expands a single integer to a vector of length `num_classes`. For large vocabularies, this can be memory-intensive.\n",
    "\n",
    "3. **Embedding Alternative**: In practice, one-hot vectors are often immediately multiplied by a weight matrix (embedding lookup). This is equivalent to selecting a row from the weight matrix using the index directly.\n",
    "\n",
    "4. **Gradient Flow**: One-hot encoding creates sparse gradients, which can be handled efficiently by deep learning frameworks.\n",
    "\n",
    "5. **Implementation Efficiency**: The identity matrix indexing approach (`np.eye(n)[indices]`) is typically faster than explicit loop-based implementations due to NumPy's optimized array operations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
