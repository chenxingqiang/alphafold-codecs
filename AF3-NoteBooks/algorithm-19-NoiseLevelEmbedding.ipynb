{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 19: Noise Level Embedding (AlphaFold3)\n",
    "\n",
    "Sinusoidal embedding for noise level in diffusion model, similar to positional encoding.\n",
    "\n",
    "## Source Code Location\n",
    "- **File**: `AF3-Ref-src/alphafold3-official/src/alphafold3/model/network/diffusion.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### Purpose\n",
    "- Encodes the current noise level t âˆˆ [0, 1] into a vector\n",
    "- Allows the network to know how much noise is present\n",
    "- Enables conditioning of all layers on noise level\n",
    "\n",
    "### Key Properties\n",
    "- Sinusoidal: Uses sin/cos of multiple frequencies\n",
    "- Continuous: Smooth representation for any t\n",
    "- Unique: Each noise level gets a distinct embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_level_embedding(t, c=256, max_period=10000):\n",
    "    \"\"\"\n",
    "    Sinusoidal noise level embedding.\n",
    "    \n",
    "    Args:\n",
    "        t: Noise level (scalar or array), typically in [0, 1]\n",
    "        c: Embedding dimension\n",
    "        max_period: Maximum period for lowest frequency\n",
    "    \n",
    "    Returns:\n",
    "        Embedding vector [c] or [batch, c]\n",
    "    \"\"\"\n",
    "    t = np.atleast_1d(t)\n",
    "    half = c // 2\n",
    "    \n",
    "    # Compute frequencies\n",
    "    freqs = np.exp(-np.log(max_period) * np.arange(half) / half)\n",
    "    \n",
    "    # Compute arguments\n",
    "    args = t[:, None] * freqs[None, :]  # [batch, half]\n",
    "    \n",
    "    # Sinusoidal embedding\n",
    "    emb = np.concatenate([np.cos(args), np.sin(args)], axis=-1)  # [batch, c]\n",
    "    \n",
    "    return emb.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_level_embedding_mlp(t, c=256, hidden=512):\n",
    "    \"\"\"\n",
    "    Noise level embedding with MLP projection.\n",
    "    \n",
    "    Often the sinusoidal embedding is passed through an MLP\n",
    "    for additional expressivity.\n",
    "    \"\"\"\n",
    "    # Base sinusoidal embedding\n",
    "    emb = noise_level_embedding(t, c)\n",
    "    \n",
    "    # MLP: Linear -> SiLU -> Linear\n",
    "    W1 = np.random.randn(c, hidden) * (c ** -0.5)\n",
    "    W2 = np.random.randn(hidden, c) * (hidden ** -0.5)\n",
    "    \n",
    "    h = emb @ W1\n",
    "    h = h / (1 + np.exp(-h))  # SiLU/Swish\n",
    "    out = h @ W2\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Embedding properties\n",
    "print(\"Test: Noise Level Embedding\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Single embedding\n",
    "t = 0.5\n",
    "emb = noise_level_embedding(t, c=64)\n",
    "print(f\"Single embedding shape: {emb.shape}\")\n",
    "print(f\"Embedding norm: {np.linalg.norm(emb):.4f}\")\n",
    "\n",
    "# Batch embedding\n",
    "t_batch = np.array([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "emb_batch = noise_level_embedding(t_batch, c=64)\n",
    "print(f\"\\nBatch embedding shape: {emb_batch.shape}\")\n",
    "\n",
    "# Check distinctness\n",
    "print(\"\\nCosine similarity between different t:\")\n",
    "for i in range(len(t_batch)):\n",
    "    for j in range(i+1, len(t_batch)):\n",
    "        sim = np.dot(emb_batch[i], emb_batch[j]) / (np.linalg.norm(emb_batch[i]) * np.linalg.norm(emb_batch[j]))\n",
    "        print(f\"  t={t_batch[i]:.2f} vs t={t_batch[j]:.2f}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings\n",
    "print(\"\\nVisualization: Noise Level Embeddings\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "t_vals = np.linspace(0, 1, 100)\n",
    "embeddings = noise_level_embedding(t_vals, c=64)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# First few dimensions\n",
    "ax = axes[0]\n",
    "for d in range(8):\n",
    "    ax.plot(t_vals, embeddings[:, d], label=f'dim {d}')\n",
    "ax.set_xlabel('Noise level t')\n",
    "ax.set_ylabel('Embedding value')\n",
    "ax.set_title('First 8 embedding dimensions')\n",
    "ax.legend()\n",
    "\n",
    "# Similarity matrix\n",
    "ax = axes[1]\n",
    "t_sample = np.linspace(0, 1, 20)\n",
    "emb_sample = noise_level_embedding(t_sample, c=64)\n",
    "sim_matrix = emb_sample @ emb_sample.T\n",
    "sim_matrix = sim_matrix / np.outer(np.linalg.norm(emb_sample, axis=1), np.linalg.norm(emb_sample, axis=1))\n",
    "im = ax.imshow(sim_matrix, cmap='viridis')\n",
    "ax.set_xlabel('t index')\n",
    "ax.set_ylabel('t index')\n",
    "ax.set_title('Cosine similarity matrix')\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/noise_embedding.png', dpi=100)\n",
    "plt.close()\n",
    "print(\"Saved visualization to /tmp/noise_embedding.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Sinusoidal**: Uses sin/cos at multiple frequencies\n",
    "2. **Smooth Interpolation**: Nearby t values have similar embeddings\n",
    "3. **Distinct**: Each noise level is uniquely represented\n",
    "4. **Conditioning**: Used throughout diffusion transformer via AdaLN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.8.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
