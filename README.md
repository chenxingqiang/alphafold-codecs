
![logo](imgs/logo2.png)
# A reference of 'AlphaFold2 Codec' include everything of AlphaFold2.

![proteins](imgs/proteins.jpeg)

------------------------------------------------------------------------------------------


# Learning Source Availability
## Papers
- [Jumper, J., Evans, R., Pritzel, A. et al. Highly accurate protein structure prediction with AlphaFold. Nature (2021). https://doi.org/10.1038/s41586-021-03819-2](https://www.nature.com/articles/s41586-021-03819-2)
  
## PPT 
- My Public talk on Alphafold2 Paper Reading By Xingqiang,Chen [.Key](https://github.com/chenxingqiang/ref-Alphafold-Code/blob/main/AF2-PPT/2021-07-30-AlphaFold2-paper-sharing-chen-xingqiang.key)/[.pptx](https://github.com/chenxingqiang/ref-Alphafold-Code/blob/main/AF2-PPT/2021-07-30-AlphaFold2-paper-sharing-chen-xingqiang.pptx)
in AF2-PPT file.
- Sergey Ovchinnikov talk on AF2 
[slides](https://docs.google.com/presentation/d/1mnffk23ev2QMDzGZ5w1skXEadTe54l8-Uei6ACce8eI/edit#slide=id.p) /[.pptx](https://github.com/chenxingqiang/ref-Alphafold-Code/blob/main/AF2-PPT/ColabFold.pptx) in AF2-PPT file.

## Learning by Code  

### ðŸ““ AlphaFold2 Algorithm Notebooks (32 Complete!)

We provide **32 Jupyter Notebooks** covering every algorithm from the AlphaFold2 supplementary materials. Each notebook includes:
- Algorithm pseudocode/image reference
- Source code location mapping
- NumPy implementation
- Executable test cases with verification

ðŸ‘‰ **[Full Algorithm Index](AF2-NoteBooks/ALGORITHM_INDEX.md)**

#### Quick Links by Category

| Category | Algorithms | Notebooks |
|----------|------------|-----------|
| **Data Preprocessing** | MSA Block Deletion | [Algorithm 1](AF2-NoteBooks/algorithm-1-MSABlockDeletion.ipynb) |
| **Embedding** | Input Embedder, relpos, one_hot | [Alg 3](AF2-NoteBooks/algorithm-3-InputEmbedder.ipynb), [Alg 4](AF2-NoteBooks/algorithm-4-relpos.ipynb), [Alg 5](AF2-NoteBooks/algorithm-5-one_hot.ipynb) |
| **Evoformer** | Stack, MSA Attention, Triangle Ops | [Alg 6-15](AF2-NoteBooks/) |
| **Templates** | Pair Stack, Pointwise Attention | [Alg 16](AF2-NoteBooks/algorithm-16-TemplatePairStack.ipynb), [Alg 17](AF2-NoteBooks/algorithm-17-TemplatePointwiseAttention.ipynb) |
| **Extra MSA** | Stack, Global Attention | [Alg 18](AF2-NoteBooks/algorithm-18-ExtraMsaStack.ipynb), [Alg 19](AF2-NoteBooks/algorithm-19-MSAColumnGlobalAttention.ipynb) |
| **Structure Module** | IPA, Backbone, Atom Coords | [Alg 20-25](AF2-NoteBooks/) |
| **Losses** | FAPE, Torsion, pLDDT | [Alg 26-29](AF2-NoteBooks/) |
| **Recycling** | Inference, Training, Embedder | [Alg 30](AF2-NoteBooks/algorithm-30-RecyclingInference.ipynb), [Alg 31](AF2-NoteBooks/algorithm-31-RecyclingTraining.ipynb), [Alg 32](AF2-NoteBooks/algorithm-32-RecyclingEmbedder.ipynb) |
| **Main Pipeline** | Full Inference | [Algorithm 2](AF2-NoteBooks/algorithm-2-Inference.ipynb) |

<details>
<summary><b>ðŸ“‹ Complete Algorithm List (Click to Expand)</b></summary>

| # | Algorithm | Notebook Link |
|---|-----------|---------------|
| 1 | MSA Block Deletion | [algorithm-1-MSABlockDeletion.ipynb](AF2-NoteBooks/algorithm-1-MSABlockDeletion.ipynb) |
| 2 | Inference | [algorithm-2-Inference.ipynb](AF2-NoteBooks/algorithm-2-Inference.ipynb) |
| 3 | Input Embedder | [algorithm-3-InputEmbedder.ipynb](AF2-NoteBooks/algorithm-3-InputEmbedder.ipynb) |
| 4 | relpos | [algorithm-4-relpos.ipynb](AF2-NoteBooks/algorithm-4-relpos.ipynb) |
| 5 | one_hot | [algorithm-5-one_hot.ipynb](AF2-NoteBooks/algorithm-5-one_hot.ipynb) |
| 6 | Evoformer Stack | [algorithm-6-EvoformerStack.ipynb](AF2-NoteBooks/algorithm-6-EvoformerStack.ipynb) |
| 7 | MSA Row Attention with Pair Bias | [algorithm-7-MSARowAttentionWithPairBias.ipynb](AF2-NoteBooks/algorithm-7-MSARowAttentionWithPairBias.ipynb) |
| 8 | MSA Column Attention | [algorithm-8-MSAColumnAttention.ipynb](AF2-NoteBooks/algorithm-8-MSAColumnAttention.ipynb) |
| 9 | MSA Transition | [algorithm-9-MSATransition.ipynb](AF2-NoteBooks/algorithm-9-MSATransition.ipynb) |
| 10 | Outer Product Mean | [algorithm-10-OuterProductMean.ipynb](AF2-NoteBooks/algorithm-10-OuterProductMean.ipynb) |
| 11 | Triangle Multiplication (Outgoing) | [algorithm-11-TriangleMultiplicationOutgoing.ipynb](AF2-NoteBooks/algorithm-11-TriangleMultiplicationOutgoing.ipynb) |
| 12 | Triangle Multiplication (Incoming) | [algorithm-12-TriangleMultiplicationIncoming.ipynb](AF2-NoteBooks/algorithm-12-TriangleMultiplicationIncoming.ipynb) |
| 13 | Triangle Attention (Starting Node) | [algorithm-13-TriangleAttentionStartingNode.ipynb](AF2-NoteBooks/algorithm-13-TriangleAttentionStartingNode.ipynb) |
| 14 | Triangle Attention (Ending Node) | [algorithm-14-TriangleAttentionEndingNode.ipynb](AF2-NoteBooks/algorithm-14-TriangleAttentionEndingNode.ipynb) |
| 15 | Pair Transition | [algorithm-15-PairTransition.ipynb](AF2-NoteBooks/algorithm-15-PairTransition.ipynb) |
| 16 | Template Pair Stack | [algorithm-16-TemplatePairStack.ipynb](AF2-NoteBooks/algorithm-16-TemplatePairStack.ipynb) |
| 17 | Template Pointwise Attention | [algorithm-17-TemplatePointwiseAttention.ipynb](AF2-NoteBooks/algorithm-17-TemplatePointwiseAttention.ipynb) |
| 18 | Extra MSA Stack | [algorithm-18-ExtraMsaStack.ipynb](AF2-NoteBooks/algorithm-18-ExtraMsaStack.ipynb) |
| 19 | MSA Column Global Attention | [algorithm-19-MSAColumnGlobalAttention.ipynb](AF2-NoteBooks/algorithm-19-MSAColumnGlobalAttention.ipynb) |
| 20 | Structure Module | [algorithm-20-StructureModule.ipynb](AF2-NoteBooks/algorithm-20-StructureModule.ipynb) |
| 21 | Rigid from 3 Points | [algorithm-21-rigidFrom3Points.ipynb](AF2-NoteBooks/algorithm-21-rigidFrom3Points.ipynb) |
| 22 | Invariant Point Attention | [algorithm-22-InvariantPointAttention.ipynb](AF2-NoteBooks/algorithm-22-InvariantPointAttention.ipynb) |
| 23 | Backbone Update | [algorithm-23-BackboneUpdate.ipynb](AF2-NoteBooks/algorithm-23-BackboneUpdate.ipynb) |
| 24 | Compute All Atom Coordinates | [algorithm-24-computeAllAtomCoordinates.ipynb](AF2-NoteBooks/algorithm-24-computeAllAtomCoordinates.ipynb) |
| 25 | makeRotX | [algorithm-25-makeRotX.ipynb](AF2-NoteBooks/algorithm-25-makeRotX.ipynb) |
| 26 | Rename Symmetric Ground Truth Atoms | [algorithm-26-renameSymmetricGroundTruthAtoms.ipynb](AF2-NoteBooks/algorithm-26-renameSymmetricGroundTruthAtoms.ipynb) |
| 27 | Torsion Angle Loss | [algorithm-27-torsionAngleLoss.ipynb](AF2-NoteBooks/algorithm-27-torsionAngleLoss.ipynb) |
| 28 | Compute FAPE | [algorithm-28-computeFAPE.ipynb](AF2-NoteBooks/algorithm-28-computeFAPE.ipynb) |
| 29 | Predict Per-Residue LDDT | [algorithm-29-predictPerResidueLDDT.ipynb](AF2-NoteBooks/algorithm-29-predictPerResidueLDDT.ipynb) |
| 30 | Recycling (Inference) | [algorithm-30-RecyclingInference.ipynb](AF2-NoteBooks/algorithm-30-RecyclingInference.ipynb) |
| 31 | Recycling (Training) | [algorithm-31-RecyclingTraining.ipynb](AF2-NoteBooks/algorithm-31-RecyclingTraining.ipynb) |
| 32 | Recycling Embedder | [algorithm-32-RecyclingEmbedder.ipynb](AF2-NoteBooks/algorithm-32-RecyclingEmbedder.ipynb) |

</details>

### ðŸ““ AlphaFold3 Algorithm Notebooks (NEW!)

We now include **AlphaFold3** algorithm notebooks! AF3 introduces significant architectural changes including diffusion-based structure prediction.

ðŸ‘‰ **[AlphaFold3 Algorithm Index](AF3-NoteBooks/ALGORITHM_INDEX.md)**

#### Key AF3 Components

| Category | Key Algorithms | Notebooks |
|----------|---------------|-----------|
| **Input** | MSA Features, Templates, Atom Features | [Alg 1-4](AF3-NoteBooks/) |
| **MSA Module** | Outer Product, MSA Attention | [Alg 5-7](AF3-NoteBooks/) |
| **Pairformer** | Triangle Ops, Single Attention | [Alg 8-14](AF3-NoteBooks/algorithm-08-PairformerStack.ipynb) |
| **Diffusion** | Diffusion Module, AdaLN, Transformer | [Alg 15](AF3-NoteBooks/algorithm-15-DiffusionModule.ipynb), [Alg 16](AF3-NoteBooks/algorithm-16-AdaptiveLayerNorm.ipynb) |
| **Confidence** | Distogram, Confidence, LDDT | [Alg 20-23](AF3-NoteBooks/) |

#### AF3 Source Code Submodules

```bash
# Official AlphaFold3
AF3-Ref-src/alphafold3-official/

# PyTorch Implementation (lucidrains)
AF3-Ref-src/alphafold3-pytorch/

# Architecture Walkthrough
AF3-Ref-src/alphafold3-walkthrough/
```

### Practice on Modeling Test of AF2
- https://github.com/sokrypton/ColabFold.git

### MD+Alphafold2
- https://github.com/pablo-arantes/Making-it-rain
## Blogs 
- [DeepMind: AlphaFold-Using-AI-for-scientific-discovery](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)
- [DeepMind: alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)
- [DeepMind: putting-the-power-of-alphafold-into-the-worlds-hands](https://deepmind.com/blog/article/putting-the-power-of-alphafold-into-the-worlds-hands)
# References 
## reference papers
- [Reference papers list](https://github.com/chenxingqiang/ref-Alphafold-Code/blob/main/AF2REFPAPERS.md) here and you can download them by [Baidu Cloud Driver Link](https://pan.baidu.com/s/131uRwemUTwGvY-6kqxCYDA) with the code 9w2p.
- [Reference Papers' Source Codes](https://github.com/chenxingqiang/ref-Alphafold-Code/tree/main/AF2-Ref-source-code) are included in this repo.



# Data availability
All input data are freely available from public sources.

Structures from the PDB were used for training and as templates (https://www.wwpdb.org/ftp/pdb-ftp-sites; for the associated sequence data and 40% sequence clustering see also https://ftp.wwpdb.org/pub/pdb/derived_data/ and https://cdn.rcsb.org/resources/sequence/clusters/bc-40.out).

 Training used a version of the PDB downloaded 28/08/2019, while CASP14 template search used a version downloaded 14/05/2020. Template search also used the PDB70 data- base, downloaded 13/05/2020 (https://wwwuser.gwdg.de/~compbiol/data/hhsuite/databases/hhsuite_dbs/).

We show experimental structures from the PDB with accessions
6Y4F<sup>76</sup>, 6YJ1<sup>77</sup>, 6VR4<sup>78</sup>, 6SK0<sup>79</sup>, 6FES<sup>80</sup>, 6W6W<sup>81</sup>, 6T1Z<sup>82</sup>, and 7JTL<sup>83</sup>. 

For MSA lookup at both training and prediction time, 

we used UniRef90 v2020_01 (https://ftp.ebi.ac.uk/pub/databases/uniprot/previous_releases/release-2020_01/uniref/), 

BFD (https://bfd.mmseqs.com), Uniclust30 v2018_08 (https://wwwuser.gwdg.de/~compbiol/uniclust/2018_08/), 

and MGnify clusters v2018_12 (https://ftp.ebi.ac.uk/pub/databases/metagenomics/peptide_database/2018_12/). Uniclust30 v2018_08 was further used as input for constructing a distillation structure dataset.


# Code and programmings availability
### Source code
 for the AlphaFold model, trained weights, and an inference script is available under an open-source license at https://github.com/deepmind/alphafold. 

### Neural networks
 Neural networks were developed with 
- TensorFlow v1 (https://github.com/tensorflow/tensorflow), 
- Sonnet v1 (https://github.com/deepmind/sonnet),
- JAX v0.1.69 (https://github.com/google/jax/), 
- Haiku v0.0.4 (https://github.com/deepmind/dm-haiku).

### MSA search
For MSA search on 
- UniRef90, MGnify clusters, 
and reduced BFD we used jackhmmer and for template search on the PDB SEQRES we used 
- hmmsearch, both from HMMER v3.3 (http://eddylab.org/soft-ware/hmmer/).

For template search against PDB70, we used HHsearch from HH-suite v3.0-beta.3 14/07/2017 (https://github.com/soedinglab/hh-suite). 
For constrained relaxation of structures, we used OpenMM v7.3.1 (https://github.com/openmm/openmm) with the Amber99sb force field.


### Docking analysis
 Docking analysis on DGAT used 
 - P2Rank v2.1 (https://github.com/rdk/p2rank), 
 - MGLTools v1.5.6 (https://ccsb.scripps.edu/mgltools/) 
 - and AutoDockVina v1.1.2 (http://vina.scripps.edu/download/) on a workstation running Debian GNU/Linux rodete 5.10.40-1rodete1-amd64 x86_64.

### Data analysis 
Data analysis used 
- Python v3.6 (https://www.python.org/), 
- NumPy v1.16.4 (https://github.com/numpy/numpy), 
- SciPy v1.2.1 (https://www.scipy.org/), 
- seaborn v0.11.1 (https://github.com/mwaskom/seaborn), 
- scikit-learn v0.24.0 (https://github.com/scikit-learn/), 
- Matplotlib v3.3.4 (https://github.com/matplotlib/matplotlib), 
- pandas v1.1.5 (https://github.com/pandas-dev/pandas), 
- and Colab (https://research.google.com/colaboratory). 
- TM-align v20190822 (https://zhanglab.dcmb.med.umich.edu/TM-align) was used for computing TM-scores.

 ### Structure analysis  
 Structure analysis used Pymol v2.3.0 (https://github.com/schrodinger/pymol-open-source).

